{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816e8dfe9a4ba016",
   "metadata": {},
   "source": [
    "# Advanced Tutorial on MetaSynth\n",
    "\n",
    "In this tutorial, we will be creating a `MetaFrame`, which is a metadata representation of a given dataset, and proceed by generating synthetic data from it. In the process, we are going to walk through some of the advanced abilities of MetaSynth, such as handling dates, setting distributions and ensuring uniqueness in columns. This example workflow starts from a `.csv` file as input, but it easily adapted to other formats. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6597b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 0: Install the metasynth package and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line and run the cell to install metasyn\n",
    "# %pip install metasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2442cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import datetime as dt\n",
    "import polars as pl\n",
    "from metasyn import MetaFrame, demo_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04466c26",
   "metadata": {},
   "source": [
    "## Step 1: Transforming your data into a polars DataFrame\n",
    "\n",
    "The first step in creating the MetaFrame is reading and converting your dataset to a polars DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2a44b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>i64</td><td>str</td><td>cat</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>cat</td><td>date</td><td>time</td><td>datetime[μs]</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Braund, Mr. Ow…</td><td>&quot;male&quot;</td><td>22</td><td>0</td><td>&quot;A/5 21171&quot;</td><td>7.25</td><td>null</td><td>&quot;S&quot;</td><td>1937-10-28</td><td>15:53:04</td><td>2022-08-05 04:43:34</td><td>null</td></tr><tr><td>2</td><td>&quot;Cumings, Mrs. …</td><td>&quot;female&quot;</td><td>38</td><td>0</td><td>&quot;PC 17599&quot;</td><td>71.2833</td><td>&quot;C85&quot;</td><td>&quot;C&quot;</td><td>null</td><td>12:26:00</td><td>2022-08-07 01:56:33</td><td>null</td></tr><tr><td>3</td><td>&quot;Heikkinen, Mis…</td><td>&quot;female&quot;</td><td>26</td><td>0</td><td>&quot;STON/O2. 31012…</td><td>7.925</td><td>null</td><td>&quot;S&quot;</td><td>1931-09-24</td><td>16:08:25</td><td>2022-08-04 20:27:37</td><td>null</td></tr><tr><td>4</td><td>&quot;Futrelle, Mrs.…</td><td>&quot;female&quot;</td><td>35</td><td>0</td><td>&quot;113803&quot;</td><td>53.1</td><td>&quot;C123&quot;</td><td>&quot;S&quot;</td><td>1936-11-30</td><td>null</td><td>2022-08-07 07:05:55</td><td>null</td></tr><tr><td>5</td><td>&quot;Allen, Mr. Wil…</td><td>&quot;male&quot;</td><td>35</td><td>0</td><td>&quot;373450&quot;</td><td>8.05</td><td>null</td><td>&quot;S&quot;</td><td>1918-11-07</td><td>10:59:08</td><td>2022-08-02 15:13:34</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌─────────────┬───────────────┬────────┬─────┬───┬────────────┬────────────┬──────────────┬────────┐\n",
       "│ PassengerId ┆ Name          ┆ Sex    ┆ Age ┆ … ┆ Birthday   ┆ Board time ┆ Married      ┆ all_NA │\n",
       "│ ---         ┆ ---           ┆ ---    ┆ --- ┆   ┆ ---        ┆ ---        ┆ since        ┆ ---    │\n",
       "│ i64         ┆ str           ┆ cat    ┆ i64 ┆   ┆ date       ┆ time       ┆ ---          ┆ str    │\n",
       "│             ┆               ┆        ┆     ┆   ┆            ┆            ┆ datetime[μs] ┆        │\n",
       "╞═════════════╪═══════════════╪════════╪═════╪═══╪════════════╪════════════╪══════════════╪════════╡\n",
       "│ 1           ┆ Braund, Mr.   ┆ male   ┆ 22  ┆ … ┆ 1937-10-28 ┆ 15:53:04   ┆ 2022-08-05   ┆ null   │\n",
       "│             ┆ Owen Harris   ┆        ┆     ┆   ┆            ┆            ┆ 04:43:34     ┆        │\n",
       "│ 2           ┆ Cumings, Mrs. ┆ female ┆ 38  ┆ … ┆ null       ┆ 12:26:00   ┆ 2022-08-07   ┆ null   │\n",
       "│             ┆ John Bradley  ┆        ┆     ┆   ┆            ┆            ┆ 01:56:33     ┆        │\n",
       "│             ┆ (Flor…        ┆        ┆     ┆   ┆            ┆            ┆              ┆        │\n",
       "│ 3           ┆ Heikkinen,    ┆ female ┆ 26  ┆ … ┆ 1931-09-24 ┆ 16:08:25   ┆ 2022-08-04   ┆ null   │\n",
       "│             ┆ Miss. Laina   ┆        ┆     ┆   ┆            ┆            ┆ 20:27:37     ┆        │\n",
       "│ 4           ┆ Futrelle,     ┆ female ┆ 35  ┆ … ┆ 1936-11-30 ┆ null       ┆ 2022-08-07   ┆ null   │\n",
       "│             ┆ Mrs. Jacques  ┆        ┆     ┆   ┆            ┆            ┆ 07:05:55     ┆        │\n",
       "│             ┆ Heath (Li…    ┆        ┆     ┆   ┆            ┆            ┆              ┆        │\n",
       "│ 5           ┆ Allen, Mr.    ┆ male   ┆ 35  ┆ … ┆ 1918-11-07 ┆ 10:59:08   ┆ 2022-08-02   ┆ null   │\n",
       "│             ┆ William Henry ┆        ┆     ┆   ┆            ┆            ┆ 15:13:34     ┆        │\n",
       "└─────────────┴───────────────┴────────┴─────┴───┴────────────┴────────────┴──────────────┴────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the path of the demo csv\n",
    "demo_file_path = demo_file()\n",
    "\n",
    "# read the data with the correct categorical variables\n",
    "data_types={\n",
    "    \"Sex\": pl.Categorical,\n",
    "    \"Embarked\": pl.Categorical\n",
    "}\n",
    "\n",
    "df = pl.read_csv(demo_file_path, try_parse_dates=True, dtypes=data_types)\n",
    "\n",
    "# check out the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2481d4",
   "metadata": {},
   "source": [
    "Now, let's check the data types of our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5a1aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PassengerId': Int64,\n",
       " 'Name': Utf8,\n",
       " 'Sex': Categorical,\n",
       " 'Age': Int64,\n",
       " 'Parch': Int64,\n",
       " 'Ticket': Utf8,\n",
       " 'Fare': Float64,\n",
       " 'Cabin': Utf8,\n",
       " 'Embarked': Categorical,\n",
       " 'Birthday': Date,\n",
       " 'Board time': Time,\n",
       " 'Married since': Datetime(time_unit='us', time_zone=None),\n",
       " 'all_NA': Utf8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(df.columns, df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebde17e",
   "metadata": {},
   "source": [
    "We see that most variables are now nicely specified as strings, categories, dates and ints where necessary. We can also inspect the data a bit more with `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72c2acb55fca193",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>891.0</td><td>&quot;891&quot;</td><td>&quot;891&quot;</td><td>891.0</td><td>891.0</td><td>&quot;891&quot;</td><td>891.0</td><td>&quot;891&quot;</td><td>&quot;891&quot;</td><td>&quot;891&quot;</td><td>&quot;891&quot;</td><td>&quot;891&quot;</td><td>&quot;891&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>177.0</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;687&quot;</td><td>&quot;2&quot;</td><td>&quot;78&quot;</td><td>&quot;79&quot;</td><td>&quot;92&quot;</td><td>&quot;891&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>446.0</td><td>null</td><td>null</td><td>29.693277</td><td>0.381594</td><td>null</td><td>32.204208</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>257.353842</td><td>null</td><td>null</td><td>14.524527</td><td>0.806057</td><td>null</td><td>49.693429</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>&quot;Abbing, Mr. An…</td><td>null</td><td>0.0</td><td>0.0</td><td>&quot;110152&quot;</td><td>0.0</td><td>&quot;A10&quot;</td><td>null</td><td>&quot;1903-07-28&quot;</td><td>&quot;10:39:40&quot;</td><td>&quot;2022-07-15 12:…</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>891.0</td><td>&quot;van Melkebeke,…</td><td>null</td><td>80.0</td><td>6.0</td><td>&quot;WE/P 5735&quot;</td><td>512.3292</td><td>&quot;T&quot;</td><td>null</td><td>&quot;1940-05-27&quot;</td><td>&quot;18:39:28&quot;</td><td>&quot;2022-08-15 10:…</td><td>null</td></tr><tr><td>&quot;median&quot;</td><td>446.0</td><td>null</td><td>null</td><td>28.0</td><td>0.0</td><td>null</td><td>14.4542</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>223.0</td><td>null</td><td>null</td><td>20.0</td><td>0.0</td><td>null</td><td>7.8958</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>669.0</td><td>null</td><td>null</td><td>38.0</td><td>0.0</td><td>null</td><td>31.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 14)\n",
       "┌────────────┬─────────────┬────────────┬──────┬───┬────────────┬────────────┬────────────┬────────┐\n",
       "│ describe   ┆ PassengerId ┆ Name       ┆ Sex  ┆ … ┆ Birthday   ┆ Board time ┆ Married    ┆ all_NA │\n",
       "│ ---        ┆ ---         ┆ ---        ┆ ---  ┆   ┆ ---        ┆ ---        ┆ since      ┆ ---    │\n",
       "│ str        ┆ f64         ┆ str        ┆ str  ┆   ┆ str        ┆ str        ┆ ---        ┆ str    │\n",
       "│            ┆             ┆            ┆      ┆   ┆            ┆            ┆ str        ┆        │\n",
       "╞════════════╪═════════════╪════════════╪══════╪═══╪════════════╪════════════╪════════════╪════════╡\n",
       "│ count      ┆ 891.0       ┆ 891        ┆ 891  ┆ … ┆ 891        ┆ 891        ┆ 891        ┆ 891    │\n",
       "│ null_count ┆ 0.0         ┆ 0          ┆ 0    ┆ … ┆ 78         ┆ 79         ┆ 92         ┆ 891    │\n",
       "│ mean       ┆ 446.0       ┆ null       ┆ null ┆ … ┆ null       ┆ null       ┆ null       ┆ null   │\n",
       "│ std        ┆ 257.353842  ┆ null       ┆ null ┆ … ┆ null       ┆ null       ┆ null       ┆ null   │\n",
       "│ min        ┆ 1.0         ┆ Abbing,    ┆ null ┆ … ┆ 1903-07-28 ┆ 10:39:40   ┆ 2022-07-15 ┆ null   │\n",
       "│            ┆             ┆ Mr.        ┆      ┆   ┆            ┆            ┆ 12:21:15   ┆        │\n",
       "│            ┆             ┆ Anthony    ┆      ┆   ┆            ┆            ┆            ┆        │\n",
       "│ max        ┆ 891.0       ┆ van        ┆ null ┆ … ┆ 1940-05-27 ┆ 18:39:28   ┆ 2022-08-15 ┆ null   │\n",
       "│            ┆             ┆ Melkebeke, ┆      ┆   ┆            ┆            ┆ 10:32:05   ┆        │\n",
       "│            ┆             ┆ Mr.        ┆      ┆   ┆            ┆            ┆            ┆        │\n",
       "│            ┆             ┆ Philemon   ┆      ┆   ┆            ┆            ┆            ┆        │\n",
       "│ median     ┆ 446.0       ┆ null       ┆ null ┆ … ┆ null       ┆ null       ┆ null       ┆ null   │\n",
       "│ 25%        ┆ 223.0       ┆ null       ┆ null ┆ … ┆ null       ┆ null       ┆ null       ┆ null   │\n",
       "│ 75%        ┆ 669.0       ┆ null       ┆ null ┆ … ┆ null       ┆ null       ┆ null       ┆ null   │\n",
       "└────────────┴─────────────┴────────────┴──────┴───┴────────────┴────────────┴────────────┴────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3f1e974e84da4",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13f849ed",
   "metadata": {},
   "source": [
    "## Step 2: Creating a MetaFrame object from a DataFrame\n",
    "\n",
    "Now a lot of work has already gone into creating a properly formatted DataFrame. This work pays off at this stage: let's convert the DataFrame to a MetaFrame structure with the default options. Note: this takes a little bit of time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c58473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qubix/Documents/shared_work/synthetic/meta-synth/metasynth/provider.py:226: UserWarning: \n",
      "Variable PassengerId seems unique, but not set to be unique.\n",
      "Set the variable to be either unique or not unique to remove this warning.\n",
      "\n",
      "  warnings.warn(f\"\\nVariable {series.name} seems unique, but not set to be unique.\\n\"\n"
     ]
    }
   ],
   "source": [
    "mf = MetaFrame.fit_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a772d",
   "metadata": {},
   "source": [
    "Then, we can simply print the MetaFrame to display it in an easy-to-read format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abab1b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rows: 891\n",
      "# Columns: 13\n",
      "\n",
      "Column 1: \"PassengerId\"\n",
      "- Variable Type: discrete\n",
      "- Data Type: Int64\n",
      "- Proportion of Missing Values: 0.0000\n",
      "- Distribution:\n",
      "\t- Type: core.discrete_uniform\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- low: 1\n",
      "\t\t- high: 892\n",
      "\t\n",
      "\n",
      "Column 2: \"Name\"\n",
      "- Variable Type: string\n",
      "- Data Type: Utf8\n",
      "- Proportion of Missing Values: 0.0000\n",
      "- Distribution:\n",
      "\t- Type: core.regex\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- regex: [A-Za-z]{1,12}(|[ \\-'][A-Z][a-z]{4,7})[,][ ][MA-Z]((|[a][s][t][e])[r]([\\.][ ][A-Z][a-z]{2,8}(|[ ][A-Z](|[a-z]{3,9}(|[ ][A-Z\\(][a-z\"]{1,8})))|[s][\\.][ ][A-Z][a-z]{3,8}[ ]([A-Z][a-z]{4,7}[ ][\\(][A-Z][a-z]{3,7}[ ][A-Z][a-z]{4,8}[\\) ]|[\\(][A-Z][a-z]{3,8}[ ][A-Z][a-z]{3,8}[\\)]))|[i][s]{2,2}[\\.][ ][A-Z][a-z]{3,8}(|[ ][A-Z][a-z]{3,8}))\n",
      "\t\n",
      "\n",
      "Column 3: \"Sex\"\n",
      "- Variable Type: categorical\n",
      "- Data Type: Categorical\n",
      "- Proportion of Missing Values: 0.0000\n",
      "- Distribution:\n",
      "\t- Type: core.multinoulli\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- labels: ['female' 'male']\n",
      "\t\t- probs: [0.35241302 0.64758698]\n",
      "\t\n",
      "\n",
      "Column 4: \"Age\"\n",
      "- Variable Type: discrete\n",
      "- Data Type: Int64\n",
      "- Proportion of Missing Values: 0.1987\n",
      "- Distribution:\n",
      "\t- Type: core.multinoulli\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "\t 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      "\t 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 70 71 74 80]\n",
      "\t\t- probs: [0.00140056 0.01820728 0.0140056  0.00840336 0.0140056  0.00560224\n",
      "\t 0.00420168 0.00420168 0.00560224 0.01120448 0.00280112 0.00560224\n",
      "\t 0.00140056 0.00280112 0.00980392 0.0070028  0.02380952 0.01820728\n",
      "\t 0.03641457 0.03501401 0.02240896 0.03361345 0.03781513 0.0210084\n",
      "\t 0.04481793 0.03221289 0.02521008 0.02521008 0.03781513 0.0280112\n",
      "\t 0.03781513 0.02380952 0.0280112  0.0210084  0.02240896 0.02521008\n",
      "\t 0.03221289 0.00840336 0.01540616 0.01960784 0.0210084  0.00840336\n",
      "\t 0.01820728 0.0070028  0.01260504 0.01680672 0.0070028  0.01260504\n",
      "\t 0.01260504 0.00840336 0.0140056  0.00980392 0.00840336 0.00140056\n",
      "\t 0.01120448 0.00280112 0.0070028  0.00280112 0.0070028  0.00280112\n",
      "\t 0.00560224 0.00420168 0.00560224 0.00280112 0.00280112 0.00420168\n",
      "\t 0.00140056 0.00420168 0.00280112 0.00140056 0.00140056]\n",
      "\t\n",
      "\n",
      "Column 5: \"Parch\"\n",
      "- Variable Type: discrete\n",
      "- Data Type: Int64\n",
      "- Proportion of Missing Values: 0.0000\n",
      "- Distribution:\n",
      "\t- Type: core.multinoulli\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- labels: [0 1 2 3 4 5 6]\n",
      "\t\t- probs: [0.76094276 0.13243547 0.08978676 0.00561167 0.00448934 0.00561167\n",
      "\t 0.00112233]\n",
      "\t\n",
      "\n",
      "Column 6: \"Ticket\"\n",
      "- Variable Type: string\n",
      "- Data Type: Utf8\n",
      "- Proportion of Missing Values: 0.0000\n",
      "- Distribution:\n",
      "\t- Type: core.regex\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- regex: (|([P][C][ ]|[CA-Z]{1,5}((|[\\.])[/][O5A-Z0-9]{1,5}(|[\\.](|[Q][\\.]))[ ](|[2][\\.][ ])|[\\.]([A][\\.][ ]|(|[CO][\\.][C][\\.])[ ])|[ ])))[0-9]{4,7}\n",
      "\t\n",
      "\n",
      "Column 7: \"Fare\"\n",
      "- Variable Type: continuous\n",
      "- Data Type: Float64\n",
      "- Proportion of Missing Values: 0.0000\n",
      "- Distribution:\n",
      "\t- Type: core.exponential\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- rate: 0.03052908440177665\n",
      "\t\n",
      "\n",
      "Column 8: \"Cabin\"\n",
      "- Variable Type: string\n",
      "- Data Type: Utf8\n",
      "- Proportion of Missing Values: 0.7710\n",
      "- Distribution:\n",
      "\t- Type: core.regex\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- regex: [A-Z][0-9]{1,3}(|[ ][B][0-9]{2,2})\n",
      "\t\n",
      "\n",
      "Column 9: \"Embarked\"\n",
      "- Variable Type: categorical\n",
      "- Data Type: Categorical\n",
      "- Proportion of Missing Values: 0.0022\n",
      "- Distribution:\n",
      "\t- Type: core.multinoulli\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- labels: ['C' 'Q' 'S']\n",
      "\t\t- probs: [0.18897638 0.08661417 0.72440945]\n",
      "\t\n",
      "\n",
      "Column 10: \"Birthday\"\n",
      "- Variable Type: date\n",
      "- Data Type: Date\n",
      "- Proportion of Missing Values: 0.0875\n",
      "- Distribution:\n",
      "\t- Type: core.uniform_date\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- start: 1903-07-28\n",
      "\t\t- end: 1940-05-27\n",
      "\t\n",
      "\n",
      "Column 11: \"Board time\"\n",
      "- Variable Type: time\n",
      "- Data Type: Time\n",
      "- Proportion of Missing Values: 0.0887\n",
      "- Distribution:\n",
      "\t- Type: core.uniform_time\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- start: 10:39:40\n",
      "\t\t- end: 18:39:28\n",
      "\t\t- precision: seconds\n",
      "\t\n",
      "\n",
      "Column 12: \"Married since\"\n",
      "- Variable Type: datetime\n",
      "- Data Type: Datetime(time_unit='us', time_zone=None)\n",
      "- Proportion of Missing Values: 0.1033\n",
      "- Distribution:\n",
      "\t- Type: core.uniform_datetime\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\t- start: 2022-07-15T12:21:15\n",
      "\t\t- end: 2022-08-15T10:32:05\n",
      "\t\t- precision: seconds\n",
      "\t\n",
      "\n",
      "Column 13: \"all_NA\"\n",
      "- Variable Type: string\n",
      "- Data Type: Utf8\n",
      "- Proportion of Missing Values: 1.0000\n",
      "- Distribution:\n",
      "\t- Type: core.na\n",
      "\t- Provenance: builtin\n",
      "\t- Parameters:\n",
      "\t\n",
      "\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3edae1eedf4b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Alternatively, we can preview the MetaFrame as it would be output to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbb6f59f1d439189",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_rows\": 891,\n",
      "    \"n_columns\": 13,\n",
      "    \"provenance\": {\n",
      "        \"created by\": {\n",
      "            \"name\": \"MetaSynth\",\n",
      "            \"version\": \"0.4.1.dev8+ga63e919.d20230816\"\n",
      "        },\n",
      "        \"creation time\": \"2023-09-13T14:45:04.605025\"\n",
      "    },\n",
      "    \"vars\": [\n",
      "        {\n",
      "            \"name\": \"PassengerId\",\n",
      "            \"type\": \"discrete\",\n",
      "            \"dtype\": \"Int64\",\n",
      "            \"prop_missing\": 0.0,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.discrete_uniform\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"DiscreteUniformDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"low\": 1,\n",
      "                    \"high\": 892\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Name\",\n",
      "            \"type\": \"string\",\n",
      "            \"dtype\": \"Utf8\",\n",
      "            \"prop_missing\": 0.0,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.regex\",\n",
      "                \"version\": \"2.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"RegexDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"regex_data\": {\n",
      "                        \"regex\": \"[A-Za-z]{1,12}(|[ \\\\-'][A-Z][a-z]{4,7})[,][ ][MA-Z]((|[a][s][t][e])[r]([\\\\.][ ][A-Z][a-z]{2,8}(|[ ][A-Z](|[a-z]{3,9}(|[ ][A-Z\\\\(][a-z\\\"]{1,8})))|[s][\\\\.][ ][A-Z][a-z]{3,8}[ ]([A-Z][a-z]{4,7}[ ][\\\\(][A-Z][a-z]{3,7}[ ][A-Z][a-z]{4,8}[\\\\) ]|[\\\\(][A-Z][a-z]{3,8}[ ][A-Z][a-z]{3,8}[\\\\)]))|[i][s]{2,2}[\\\\.][ ][A-Z][a-z]{3,8}(|[ ][A-Z][a-z]{3,8}))\",\n",
      "                        \"counts\": [\n",
      "                            22,\n",
      "                            [\n",
      "                                [\n",
      "                                    160\n",
      "                                ],\n",
      "                                [\n",
      "                                    22,\n",
      "                                    22,\n",
      "                                    22,\n",
      "                                    22\n",
      "                                ]\n",
      "                            ],\n",
      "                            160,\n",
      "                            160,\n",
      "                            160,\n",
      "                            [\n",
      "                                [\n",
      "                                    [\n",
      "                                        [\n",
      "                                            493\n",
      "                                        ],\n",
      "                                        [\n",
      "                                            33,\n",
      "                                            33,\n",
      "                                            33,\n",
      "                                            33,\n",
      "                                            33\n",
      "                                        ]\n",
      "                                    ],\n",
      "                                    493,\n",
      "                                    [\n",
      "                                        [\n",
      "                                            464,\n",
      "                                            464,\n",
      "                                            464,\n",
      "                                            464,\n",
      "                                            [\n",
      "                                                [\n",
      "                                                    209\n",
      "                                                ],\n",
      "                                                [\n",
      "                                                    255,\n",
      "                                                    255,\n",
      "                                                    [\n",
      "                                                        [\n",
      "                                                            20\n",
      "                                                        ],\n",
      "                                                        [\n",
      "                                                            235,\n",
      "                                                            [\n",
      "                                                                [\n",
      "                                                                    212\n",
      "                                                                ],\n",
      "                                                                [\n",
      "                                                                    23,\n",
      "                                                                    23,\n",
      "                                                                    23,\n",
      "                                                                    23\n",
      "                                                                ]\n",
      "                                                            ],\n",
      "                                                            0\n",
      "                                                        ]\n",
      "                                                    ],\n",
      "                                                    0\n",
      "                                                ]\n",
      "                                            ],\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        [\n",
      "                                            29,\n",
      "                                            29,\n",
      "                                            29,\n",
      "                                            29,\n",
      "                                            29,\n",
      "                                            29,\n",
      "                                            [\n",
      "                                                [\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13,\n",
      "                                                    13\n",
      "                                                ],\n",
      "                                                [\n",
      "                                                    16,\n",
      "                                                    16,\n",
      "                                                    16,\n",
      "                                                    16,\n",
      "                                                    16,\n",
      "                                                    16,\n",
      "                                                    16,\n",
      "                                                    16\n",
      "                                                ]\n",
      "                                            ],\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    ],\n",
      "                                    0\n",
      "                                ],\n",
      "                                [\n",
      "                                    127,\n",
      "                                    127,\n",
      "                                    127,\n",
      "                                    127,\n",
      "                                    127,\n",
      "                                    127,\n",
      "                                    [\n",
      "                                        [\n",
      "                                            64\n",
      "                                        ],\n",
      "                                        [\n",
      "                                            63,\n",
      "                                            63,\n",
      "                                            63,\n",
      "                                            63\n",
      "                                        ]\n",
      "                                    ],\n",
      "                                    0\n",
      "                                ]\n",
      "                            ],\n",
      "                            0\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Sex\",\n",
      "            \"type\": \"categorical\",\n",
      "            \"dtype\": \"Categorical\",\n",
      "            \"prop_missing\": 0.0,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.multinoulli\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"MultinoulliDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"labels\": [\n",
      "                        \"female\",\n",
      "                        \"male\"\n",
      "                    ],\n",
      "                    \"probs\": [\n",
      "                        0.35241301907968575,\n",
      "                        0.6475869809203143\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Age\",\n",
      "            \"type\": \"discrete\",\n",
      "            \"dtype\": \"Int64\",\n",
      "            \"prop_missing\": 0.19865319865319866,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.multinoulli\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"MultinoulliDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"labels\": [\n",
      "                        0,\n",
      "                        1,\n",
      "                        2,\n",
      "                        3,\n",
      "                        4,\n",
      "                        5,\n",
      "                        6,\n",
      "                        7,\n",
      "                        8,\n",
      "                        9,\n",
      "                        10,\n",
      "                        11,\n",
      "                        12,\n",
      "                        13,\n",
      "                        14,\n",
      "                        15,\n",
      "                        16,\n",
      "                        17,\n",
      "                        18,\n",
      "                        19,\n",
      "                        20,\n",
      "                        21,\n",
      "                        22,\n",
      "                        23,\n",
      "                        24,\n",
      "                        25,\n",
      "                        26,\n",
      "                        27,\n",
      "                        28,\n",
      "                        29,\n",
      "                        30,\n",
      "                        31,\n",
      "                        32,\n",
      "                        33,\n",
      "                        34,\n",
      "                        35,\n",
      "                        36,\n",
      "                        37,\n",
      "                        38,\n",
      "                        39,\n",
      "                        40,\n",
      "                        41,\n",
      "                        42,\n",
      "                        43,\n",
      "                        44,\n",
      "                        45,\n",
      "                        46,\n",
      "                        47,\n",
      "                        48,\n",
      "                        49,\n",
      "                        50,\n",
      "                        51,\n",
      "                        52,\n",
      "                        53,\n",
      "                        54,\n",
      "                        55,\n",
      "                        56,\n",
      "                        57,\n",
      "                        58,\n",
      "                        59,\n",
      "                        60,\n",
      "                        61,\n",
      "                        62,\n",
      "                        63,\n",
      "                        64,\n",
      "                        65,\n",
      "                        66,\n",
      "                        70,\n",
      "                        71,\n",
      "                        74,\n",
      "                        80\n",
      "                    ],\n",
      "                    \"probs\": [\n",
      "                        0.0014005602240896359,\n",
      "                        0.018207282913165267,\n",
      "                        0.014005602240896359,\n",
      "                        0.008403361344537815,\n",
      "                        0.014005602240896359,\n",
      "                        0.0056022408963585435,\n",
      "                        0.004201680672268907,\n",
      "                        0.004201680672268907,\n",
      "                        0.0056022408963585435,\n",
      "                        0.011204481792717087,\n",
      "                        0.0028011204481792717,\n",
      "                        0.0056022408963585435,\n",
      "                        0.0014005602240896359,\n",
      "                        0.0028011204481792717,\n",
      "                        0.00980392156862745,\n",
      "                        0.0070028011204481795,\n",
      "                        0.023809523809523808,\n",
      "                        0.018207282913165267,\n",
      "                        0.036414565826330535,\n",
      "                        0.0350140056022409,\n",
      "                        0.022408963585434174,\n",
      "                        0.03361344537815126,\n",
      "                        0.037815126050420166,\n",
      "                        0.02100840336134454,\n",
      "                        0.04481792717086835,\n",
      "                        0.03221288515406162,\n",
      "                        0.025210084033613446,\n",
      "                        0.025210084033613446,\n",
      "                        0.037815126050420166,\n",
      "                        0.028011204481792718,\n",
      "                        0.037815126050420166,\n",
      "                        0.023809523809523808,\n",
      "                        0.028011204481792718,\n",
      "                        0.02100840336134454,\n",
      "                        0.022408963585434174,\n",
      "                        0.025210084033613446,\n",
      "                        0.03221288515406162,\n",
      "                        0.008403361344537815,\n",
      "                        0.015406162464985995,\n",
      "                        0.0196078431372549,\n",
      "                        0.02100840336134454,\n",
      "                        0.008403361344537815,\n",
      "                        0.018207282913165267,\n",
      "                        0.0070028011204481795,\n",
      "                        0.012605042016806723,\n",
      "                        0.01680672268907563,\n",
      "                        0.0070028011204481795,\n",
      "                        0.012605042016806723,\n",
      "                        0.012605042016806723,\n",
      "                        0.008403361344537815,\n",
      "                        0.014005602240896359,\n",
      "                        0.00980392156862745,\n",
      "                        0.008403361344537815,\n",
      "                        0.0014005602240896359,\n",
      "                        0.011204481792717087,\n",
      "                        0.0028011204481792717,\n",
      "                        0.0070028011204481795,\n",
      "                        0.0028011204481792717,\n",
      "                        0.0070028011204481795,\n",
      "                        0.0028011204481792717,\n",
      "                        0.0056022408963585435,\n",
      "                        0.004201680672268907,\n",
      "                        0.0056022408963585435,\n",
      "                        0.0028011204481792717,\n",
      "                        0.0028011204481792717,\n",
      "                        0.004201680672268907,\n",
      "                        0.0014005602240896359,\n",
      "                        0.004201680672268907,\n",
      "                        0.0028011204481792717,\n",
      "                        0.0014005602240896359,\n",
      "                        0.0014005602240896359\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Parch\",\n",
      "            \"type\": \"discrete\",\n",
      "            \"dtype\": \"Int64\",\n",
      "            \"prop_missing\": 0.0,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.multinoulli\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"MultinoulliDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"labels\": [\n",
      "                        0,\n",
      "                        1,\n",
      "                        2,\n",
      "                        3,\n",
      "                        4,\n",
      "                        5,\n",
      "                        6\n",
      "                    ],\n",
      "                    \"probs\": [\n",
      "                        0.760942760942761,\n",
      "                        0.13243546576879914,\n",
      "                        0.08978675645342313,\n",
      "                        0.0056116722783389455,\n",
      "                        0.004489337822671157,\n",
      "                        0.0056116722783389455,\n",
      "                        0.0011223344556677893\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Ticket\",\n",
      "            \"type\": \"string\",\n",
      "            \"dtype\": \"Utf8\",\n",
      "            \"prop_missing\": 0.0,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.regex\",\n",
      "                \"version\": \"2.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"RegexDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"regex_data\": {\n",
      "                        \"regex\": \"(|([P][C][ ]|[CA-Z]{1,5}((|[\\\\.])[/][O5A-Z0-9]{1,5}(|[\\\\.](|[Q][\\\\.]))[ ](|[2][\\\\.][ ])|[\\\\.]([A][\\\\.][ ]|(|[CO][\\\\.][C][\\\\.])[ ])|[ ])))[0-9]{4,7}\",\n",
      "                        \"counts\": [\n",
      "                            [\n",
      "                                [\n",
      "                                    659\n",
      "                                ],\n",
      "                                [\n",
      "                                    [\n",
      "                                        [\n",
      "                                            60,\n",
      "                                            60,\n",
      "                                            60,\n",
      "                                            60\n",
      "                                        ],\n",
      "                                        [\n",
      "                                            60,\n",
      "                                            [\n",
      "                                                [\n",
      "                                                    [\n",
      "                                                        [\n",
      "                                                            23\n",
      "                                                        ],\n",
      "                                                        [\n",
      "                                                            11,\n",
      "                                                            11\n",
      "                                                        ]\n",
      "                                                    ],\n",
      "                                                    23,\n",
      "                                                    23,\n",
      "                                                    [\n",
      "                                                        [\n",
      "                                                            47\n",
      "                                                        ],\n",
      "                                                        [\n",
      "                                                            23,\n",
      "                                                            [\n",
      "                                                                [\n",
      "                                                                    15\n",
      "                                                                ],\n",
      "                                                                [\n",
      "                                                                    8,\n",
      "                                                                    8,\n",
      "                                                                    8\n",
      "                                                                ]\n",
      "                                                            ],\n",
      "                                                            0\n",
      "                                                        ]\n",
      "                                                    ],\n",
      "                                                    47,\n",
      "                                                    [\n",
      "                                                        [\n",
      "                                                            35\n",
      "                                                        ],\n",
      "                                                        [\n",
      "                                                            12,\n",
      "                                                            12,\n",
      "                                                            12,\n",
      "                                                            12\n",
      "                                                        ]\n",
      "                                                    ],\n",
      "                                                    0\n",
      "                                                ],\n",
      "                                                [\n",
      "                                                    37,\n",
      "                                                    [\n",
      "                                                        [\n",
      "                                                            27,\n",
      "                                                            27,\n",
      "                                                            27,\n",
      "                                                            27\n",
      "                                                        ],\n",
      "                                                        [\n",
      "                                                            [\n",
      "                                                                [\n",
      "                                                                    8\n",
      "                                                                ],\n",
      "                                                                [\n",
      "                                                                    10,\n",
      "                                                                    10,\n",
      "                                                                    10,\n",
      "                                                                    10,\n",
      "                                                                    10\n",
      "                                                                ]\n",
      "                                                            ],\n",
      "                                                            8,\n",
      "                                                            8\n",
      "                                                        ]\n",
      "                                                    ],\n",
      "                                                    0\n",
      "                                                ],\n",
      "                                                [\n",
      "                                                    12,\n",
      "                                                    12\n",
      "                                                ]\n",
      "                                            ],\n",
      "                                            0\n",
      "                                        ]\n",
      "                                    ],\n",
      "                                    0\n",
      "                                ]\n",
      "                            ],\n",
      "                            659,\n",
      "                            659\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Fare\",\n",
      "            \"type\": \"continuous\",\n",
      "            \"dtype\": \"Float64\",\n",
      "            \"prop_missing\": 0.0,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.exponential\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"ExponentialDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"rate\": 0.03052908440177665\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Cabin\",\n",
      "            \"type\": \"string\",\n",
      "            \"dtype\": \"Utf8\",\n",
      "            \"prop_missing\": 0.7710437710437711,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.regex\",\n",
      "                \"version\": \"2.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"RegexDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"regex_data\": {\n",
      "                        \"regex\": \"[A-Z][0-9]{1,3}(|[ ][B][0-9]{2,2})\",\n",
      "                        \"counts\": [\n",
      "                            183,\n",
      "                            183,\n",
      "                            [\n",
      "                                [\n",
      "                                    176\n",
      "                                ],\n",
      "                                [\n",
      "                                    7,\n",
      "                                    7,\n",
      "                                    7,\n",
      "                                    7\n",
      "                                ]\n",
      "                            ],\n",
      "                            0\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Embarked\",\n",
      "            \"type\": \"categorical\",\n",
      "            \"dtype\": \"Categorical\",\n",
      "            \"prop_missing\": 0.002244668911335578,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.multinoulli\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"MultinoulliDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"labels\": [\n",
      "                        \"C\",\n",
      "                        \"Q\",\n",
      "                        \"S\"\n",
      "                    ],\n",
      "                    \"probs\": [\n",
      "                        0.1889763779527559,\n",
      "                        0.08661417322834646,\n",
      "                        0.7244094488188977\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Birthday\",\n",
      "            \"type\": \"date\",\n",
      "            \"dtype\": \"Date\",\n",
      "            \"prop_missing\": 0.08754208754208755,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.uniform_date\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"UniformDateDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"start\": \"1903-07-28\",\n",
      "                    \"end\": \"1940-05-27\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Board time\",\n",
      "            \"type\": \"time\",\n",
      "            \"dtype\": \"Time\",\n",
      "            \"prop_missing\": 0.08866442199775533,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.uniform_time\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"UniformTimeDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"start\": \"10:39:40\",\n",
      "                    \"end\": \"18:39:28\",\n",
      "                    \"precision\": \"seconds\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Married since\",\n",
      "            \"type\": \"datetime\",\n",
      "            \"dtype\": \"Datetime(time_unit='us', time_zone=None)\",\n",
      "            \"prop_missing\": 0.10325476992143659,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.uniform_datetime\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"UniformDateTimeDistribution\",\n",
      "                \"parameters\": {\n",
      "                    \"start\": \"2022-07-15T12:21:15\",\n",
      "                    \"end\": \"2022-08-15T10:32:05\",\n",
      "                    \"precision\": \"seconds\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"all_NA\",\n",
      "            \"type\": \"string\",\n",
      "            \"dtype\": \"Utf8\",\n",
      "            \"prop_missing\": 1.0,\n",
      "            \"distribution\": {\n",
      "                \"implements\": \"core.na\",\n",
      "                \"version\": \"1.0\",\n",
      "                \"provenance\": \"builtin\",\n",
      "                \"class_name\": \"NADistribution\",\n",
      "                \"parameters\": {}\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_preview = repr(mf)\n",
    "print(json_preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b27a95",
   "metadata": {},
   "source": [
    "## Step 3: Saving the metadata in a file\n",
    "\n",
    "After creating the MetaFrame, we can save it to a file. The default format is `JSON`, which is both easy to read for humans and computers. This allows one to manually inspect the metadata file and verify no sensitive information would be shared. If the disclosure risk is deemed low, the JSON file can then be securely provided to others for exploratory analysis or other uses without exposing private data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e355f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the metadata to a file\n",
    "file_path = \"demonstration_metadata.json\"\n",
    "mf.to_json(file_path)\n",
    "\n",
    "# you can now open and read the json file!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571873d",
   "metadata": {},
   "source": [
    "## Step 4: Generating synthetic data from the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd16a5a",
   "metadata": {},
   "source": [
    "A previously exported MetaFrame (.json) file can be loaded into a MetaFrame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5eac7eeb3326f03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load previously exported MetaFrame (.json) file\n",
    "mf = MetaFrame.from_json(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85201666a67a73fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Once a MetaFrame is loaded, synthetic data can be generated from it. The `synthesize` method takes the number of rows to be generated as parameter and returns a DataFrame with the synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ccf451c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>i64</td><td>str</td><td>cat</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>cat</td><td>date</td><td>time</td><td>datetime[μs]</td><td>f32</td></tr></thead><tbody><tr><td>882</td><td>&quot;uhBLYhXVL, Xr.…</td><td>&quot;male&quot;</td><td>null</td><td>0</td><td>&quot;756153&quot;</td><td>0.610886</td><td>&quot;K13&quot;</td><td>&quot;S&quot;</td><td>1917-01-19</td><td>12:14:36</td><td>2022-08-03 09:54:15</td><td>null</td></tr><tr><td>205</td><td>&quot;jyn, Cr. Udm&quot;</td><td>&quot;female&quot;</td><td>24</td><td>0</td><td>&quot;19449&quot;</td><td>40.455172</td><td>null</td><td>&quot;S&quot;</td><td>1908-07-29</td><td>15:48:17</td><td>2022-07-21 22:42:43</td><td>null</td></tr><tr><td>814</td><td>&quot;Jh, Er. Umvyb …</td><td>&quot;male&quot;</td><td>48</td><td>0</td><td>&quot;96094&quot;</td><td>35.064438</td><td>null</td><td>&quot;C&quot;</td><td>1935-02-26</td><td>14:14:19</td><td>2022-08-05 11:16:39</td><td>null</td></tr><tr><td>546</td><td>&quot;zOfek, Kr. Kyz…</td><td>&quot;male&quot;</td><td>20</td><td>0</td><td>&quot;7269&quot;</td><td>50.017058</td><td>&quot;C71&quot;</td><td>&quot;S&quot;</td><td>1922-12-02</td><td>14:14:09</td><td>null</td><td>null</td></tr><tr><td>11</td><td>&quot;pTa-Bdxwuh, Vr…</td><td>&quot;male&quot;</td><td>30</td><td>0</td><td>&quot;86867&quot;</td><td>12.834675</td><td>null</td><td>&quot;S&quot;</td><td>1905-01-26</td><td>14:35:07</td><td>2022-07-22 11:00:34</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌─────────────┬──────────────┬────────┬──────┬───┬────────────┬────────────┬──────────────┬────────┐\n",
       "│ PassengerId ┆ Name         ┆ Sex    ┆ Age  ┆ … ┆ Birthday   ┆ Board time ┆ Married      ┆ all_NA │\n",
       "│ ---         ┆ ---          ┆ ---    ┆ ---  ┆   ┆ ---        ┆ ---        ┆ since        ┆ ---    │\n",
       "│ i64         ┆ str          ┆ cat    ┆ i64  ┆   ┆ date       ┆ time       ┆ ---          ┆ f32    │\n",
       "│             ┆              ┆        ┆      ┆   ┆            ┆            ┆ datetime[μs] ┆        │\n",
       "╞═════════════╪══════════════╪════════╪══════╪═══╪════════════╪════════════╪══════════════╪════════╡\n",
       "│ 882         ┆ uhBLYhXVL,   ┆ male   ┆ null ┆ … ┆ 1917-01-19 ┆ 12:14:36   ┆ 2022-08-03   ┆ null   │\n",
       "│             ┆ Xr. Svv      ┆        ┆      ┆   ┆            ┆            ┆ 09:54:15     ┆        │\n",
       "│ 205         ┆ jyn, Cr. Udm ┆ female ┆ 24   ┆ … ┆ 1908-07-29 ┆ 15:48:17   ┆ 2022-07-21   ┆ null   │\n",
       "│             ┆              ┆        ┆      ┆   ┆            ┆            ┆ 22:42:43     ┆        │\n",
       "│ 814         ┆ Jh, Er.      ┆ male   ┆ 48   ┆ … ┆ 1935-02-26 ┆ 14:14:19   ┆ 2022-08-05   ┆ null   │\n",
       "│             ┆ Umvyb        ┆        ┆      ┆   ┆            ┆            ┆ 11:16:39     ┆        │\n",
       "│             ┆ Gnijluk Rlxw ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "│ 546         ┆ zOfek, Kr.   ┆ male   ┆ 20   ┆ … ┆ 1922-12-02 ┆ 14:14:09   ┆ null         ┆ null   │\n",
       "│             ┆ Kyzmeetqv    ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "│             ┆ Iizy         ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "│ 11          ┆ pTa-Bdxwuh,  ┆ male   ┆ 30   ┆ … ┆ 1905-01-26 ┆ 14:35:07   ┆ 2022-07-22   ┆ null   │\n",
       "│             ┆ Vr. Lzpw     ┆        ┆      ┆   ┆            ┆            ┆ 11:00:34     ┆        │\n",
       "│             ┆ Ovexjj       ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "└─────────────┴──────────────┴────────┴──────┴───┴────────────┴────────────┴──────────────┴────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate synthetic data\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b1e95",
   "metadata": {},
   "source": [
    "As you can see, the fake data looks a lot like the real data! However, it could still use some improvement. In the next sections, we will explore manual changes we can make to improve the quality of the synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cfe6cd",
   "metadata": {},
   "source": [
    "## Step 5: Improving the quality of the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32cc3a",
   "metadata": {},
   "source": [
    "### Set unique columns\n",
    "\n",
    "One column (PassengerId) has been detected as possibly unique by MetaSynth, as indicated by the following warning:\n",
    "\n",
    "> \"Variable PassengerId seems unique, but not set to be unique.\"\n",
    "\n",
    "This column holds a variable with unique passenger identifiers, so in fact we do want synthetic data generated for this column to be unique as well. We can add this to the metadata by creating a list of options which we call a `specification`, or `spec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b76751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'PassengerId',\n",
       " 'type': 'discrete',\n",
       " 'dtype': 'Int64',\n",
       " 'prop_missing': 0.0,\n",
       " 'distribution': {'implements': 'core.unique_key',\n",
       "  'version': '1.0',\n",
       "  'provenance': 'builtin',\n",
       "  'class_name': 'UniqueKeyDistribution',\n",
       "  'parameters': {'low': 1, 'consecutive': 1}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we create a specification dictionary for the variables\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}\n",
    "}\n",
    "\n",
    "# then, we add that dictionary as the `spec` argument\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "\n",
    "# then, let's check what the metadata about PassengerId contains!\n",
    "mf[\"PassengerId\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f0970",
   "metadata": {},
   "source": [
    "So let's check what is generated from this new MetaFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c2f4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>i64</td><td>str</td><td>cat</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>f32</td><td>cat</td><td>date</td><td>time</td><td>datetime[μs]</td><td>f32</td></tr></thead><tbody><tr><td>1</td><td>&quot;awKEOdy, Piss.…</td><td>&quot;male&quot;</td><td>17</td><td>0</td><td>&quot;TJA.A. 410408&quot;</td><td>13.313988</td><td>null</td><td>&quot;Q&quot;</td><td>1911-12-26</td><td>13:09:25</td><td>null</td><td>null</td></tr><tr><td>2</td><td>&quot;bIkjxdIovjvN, …</td><td>&quot;male&quot;</td><td>22</td><td>0</td><td>&quot;9612267&quot;</td><td>7.113703</td><td>null</td><td>&quot;S&quot;</td><td>1909-11-17</td><td>16:10:29</td><td>2022-07-30 21:16:53</td><td>null</td></tr><tr><td>3</td><td>&quot;tKTVPTthhD, Nr…</td><td>&quot;female&quot;</td><td>47</td><td>1</td><td>&quot;8054&quot;</td><td>36.150274</td><td>null</td><td>&quot;S&quot;</td><td>1904-11-24</td><td>13:06:47</td><td>null</td><td>null</td></tr><tr><td>4</td><td>&quot;zR, Iiss. Lkjq…</td><td>&quot;male&quot;</td><td>null</td><td>0</td><td>&quot;9175&quot;</td><td>5.522355</td><td>null</td><td>&quot;C&quot;</td><td>1906-05-26</td><td>12:21:26</td><td>2022-08-11 19:38:25</td><td>null</td></tr><tr><td>5</td><td>&quot;VZFXHGcyDySP, …</td><td>&quot;female&quot;</td><td>57</td><td>0</td><td>&quot;24396&quot;</td><td>14.28513</td><td>null</td><td>&quot;S&quot;</td><td>1940-05-21</td><td>17:00:47</td><td>2022-07-30 20:57:49</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌─────────────┬──────────────┬────────┬──────┬───┬────────────┬────────────┬──────────────┬────────┐\n",
       "│ PassengerId ┆ Name         ┆ Sex    ┆ Age  ┆ … ┆ Birthday   ┆ Board time ┆ Married      ┆ all_NA │\n",
       "│ ---         ┆ ---          ┆ ---    ┆ ---  ┆   ┆ ---        ┆ ---        ┆ since        ┆ ---    │\n",
       "│ i64         ┆ str          ┆ cat    ┆ i64  ┆   ┆ date       ┆ time       ┆ ---          ┆ f32    │\n",
       "│             ┆              ┆        ┆      ┆   ┆            ┆            ┆ datetime[μs] ┆        │\n",
       "╞═════════════╪══════════════╪════════╪══════╪═══╪════════════╪════════════╪══════════════╪════════╡\n",
       "│ 1           ┆ awKEOdy,     ┆ male   ┆ 17   ┆ … ┆ 1911-12-26 ┆ 13:09:25   ┆ null         ┆ null   │\n",
       "│             ┆ Piss.        ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "│             ┆ Egkbmupk     ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "│ 2           ┆ bIkjxdIovjvN ┆ male   ┆ 22   ┆ … ┆ 1909-11-17 ┆ 16:10:29   ┆ 2022-07-30   ┆ null   │\n",
       "│             ┆ , Siss.      ┆        ┆      ┆   ┆            ┆            ┆ 21:16:53     ┆        │\n",
       "│             ┆ Vhyvn        ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "│ 3           ┆ tKTVPTthhD,  ┆ female ┆ 47   ┆ … ┆ 1904-11-24 ┆ 13:06:47   ┆ null         ┆ null   │\n",
       "│             ┆ Nr. Jjagaay  ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "│ 4           ┆ zR, Iiss.    ┆ male   ┆ null ┆ … ┆ 1906-05-26 ┆ 12:21:26   ┆ 2022-08-11   ┆ null   │\n",
       "│             ┆ Lkjqviyb     ┆        ┆      ┆   ┆            ┆            ┆ 19:38:25     ┆        │\n",
       "│ 5           ┆ VZFXHGcyDySP ┆ female ┆ 57   ┆ … ┆ 1940-05-21 ┆ 17:00:47   ┆ 2022-07-30   ┆ null   │\n",
       "│             ┆ , Liss.      ┆        ┆      ┆   ┆            ┆            ┆ 20:57:49     ┆        │\n",
       "│             ┆ Iontxplh     ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "└─────────────┴──────────────┴────────┴──────┴───┴────────────┴────────────┴──────────────┴────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7f562",
   "metadata": {},
   "source": [
    "Now we that the `PassengerId` column is correctly represented with increasing id numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f884eb7",
   "metadata": {},
   "source": [
    "### Fake names (and others)\n",
    "\n",
    "As one can see, the `Name` of the passengers is not quite so well synthesized. The reason is that the string type interpreter in MetaSynth is designed for `structured` strings (like room numbers such as `B1.09`, `B1.01` or `A1.08`) and not unstructured strings. However, MetaSynth supports the [faker](https://faker.readthedocs.io/en/master/index.html) package, which includes a lot of data types that it can fake. The columns using faker are not based on the real data at all so they do not disclose any info about the real data.\n",
    "\n",
    "We fake names as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5615aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>i64</td><td>str</td><td>cat</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>f32</td><td>cat</td><td>date</td><td>time</td><td>datetime[μs]</td><td>f32</td></tr></thead><tbody><tr><td>1</td><td>&quot;Michael Morale…</td><td>&quot;male&quot;</td><td>27</td><td>0</td><td>&quot;9256&quot;</td><td>52.678668</td><td>null</td><td>&quot;S&quot;</td><td>1925-10-10</td><td>10:40:23</td><td>2022-08-14 08:16:50</td><td>null</td></tr><tr><td>2</td><td>&quot;Barbara Curtis…</td><td>&quot;female&quot;</td><td>22</td><td>0</td><td>&quot;399720&quot;</td><td>185.674337</td><td>null</td><td>&quot;S&quot;</td><td>1910-11-22</td><td>16:33:16</td><td>2022-07-28 04:42:43</td><td>null</td></tr><tr><td>3</td><td>&quot;Kelsey Sanchez…</td><td>&quot;male&quot;</td><td>24</td><td>0</td><td>&quot;ZR.A. 8795835&quot;</td><td>20.583335</td><td>null</td><td>&quot;S&quot;</td><td>1933-01-26</td><td>null</td><td>2022-08-11 17:15:46</td><td>null</td></tr><tr><td>4</td><td>&quot;Dr. Glen Woods…</td><td>&quot;male&quot;</td><td>1</td><td>2</td><td>&quot;3967698&quot;</td><td>99.910127</td><td>null</td><td>&quot;S&quot;</td><td>1914-11-23</td><td>10:51:31</td><td>2022-07-28 02:39:19</td><td>null</td></tr><tr><td>5</td><td>&quot;Monica Kirby&quot;</td><td>&quot;female&quot;</td><td>2</td><td>0</td><td>&quot;573728&quot;</td><td>18.63288</td><td>null</td><td>&quot;S&quot;</td><td>1935-02-02</td><td>11:08:08</td><td>2022-07-17 01:43:02</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌─────────────┬───────────────┬────────┬─────┬───┬────────────┬────────────┬──────────────┬────────┐\n",
       "│ PassengerId ┆ Name          ┆ Sex    ┆ Age ┆ … ┆ Birthday   ┆ Board time ┆ Married      ┆ all_NA │\n",
       "│ ---         ┆ ---           ┆ ---    ┆ --- ┆   ┆ ---        ┆ ---        ┆ since        ┆ ---    │\n",
       "│ i64         ┆ str           ┆ cat    ┆ i64 ┆   ┆ date       ┆ time       ┆ ---          ┆ f32    │\n",
       "│             ┆               ┆        ┆     ┆   ┆            ┆            ┆ datetime[μs] ┆        │\n",
       "╞═════════════╪═══════════════╪════════╪═════╪═══╪════════════╪════════════╪══════════════╪════════╡\n",
       "│ 1           ┆ Michael       ┆ male   ┆ 27  ┆ … ┆ 1925-10-10 ┆ 10:40:23   ┆ 2022-08-14   ┆ null   │\n",
       "│             ┆ Morales       ┆        ┆     ┆   ┆            ┆            ┆ 08:16:50     ┆        │\n",
       "│ 2           ┆ Barbara       ┆ female ┆ 22  ┆ … ┆ 1910-11-22 ┆ 16:33:16   ┆ 2022-07-28   ┆ null   │\n",
       "│             ┆ Curtis        ┆        ┆     ┆   ┆            ┆            ┆ 04:42:43     ┆        │\n",
       "│ 3           ┆ Kelsey        ┆ male   ┆ 24  ┆ … ┆ 1933-01-26 ┆ null       ┆ 2022-08-11   ┆ null   │\n",
       "│             ┆ Sanchez       ┆        ┆     ┆   ┆            ┆            ┆ 17:15:46     ┆        │\n",
       "│ 4           ┆ Dr. Glen      ┆ male   ┆ 1   ┆ … ┆ 1914-11-23 ┆ 10:51:31   ┆ 2022-07-28   ┆ null   │\n",
       "│             ┆ Woods         ┆        ┆     ┆   ┆            ┆            ┆ 02:39:19     ┆        │\n",
       "│ 5           ┆ Monica Kirby  ┆ female ┆ 2   ┆ … ┆ 1935-02-02 ┆ 11:08:08   ┆ 2022-07-17   ┆ null   │\n",
       "│             ┆               ┆        ┆     ┆   ┆            ┆            ┆ 01:43:02     ┆        │\n",
       "└─────────────┴───────────────┴────────┴─────┴───┴────────────┴────────────┴──────────────┴────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we create a specification dictionary for the variables\n",
    "from metasyn.distribution import FakerDistribution\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")}\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1fa66b",
   "metadata": {},
   "source": [
    "That already looks a lot better for the `Name` column!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf927af6",
   "metadata": {},
   "source": [
    "### Set distributions manually\n",
    "\n",
    "Without user input, the distribution chosen for each variable is inferred by choosing the best fitting from available distributions for the variable type. However, we can also manually specify which distribution to fit, or we can even just fully specify how the variable should be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac4ba506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>i64</td><td>str</td><td>cat</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>cat</td><td>date</td><td>time</td><td>datetime[μs]</td><td>f32</td></tr></thead><tbody><tr><td>1</td><td>&quot;Michael Morale…</td><td>&quot;male&quot;</td><td>21</td><td>0</td><td>&quot;0830164&quot;</td><td>4.594758</td><td>&quot;N6&quot;</td><td>&quot;S&quot;</td><td>null</td><td>10:42:12</td><td>2022-08-11 05:48:20</td><td>null</td></tr><tr><td>2</td><td>&quot;Barbara Curtis…</td><td>&quot;female&quot;</td><td>null</td><td>0</td><td>&quot;08899&quot;</td><td>0.65618</td><td>&quot;G49&quot;</td><td>&quot;S&quot;</td><td>1905-01-25</td><td>14:27:45</td><td>2022-07-30 10:46:53</td><td>null</td></tr><tr><td>3</td><td>&quot;Kelsey Sanchez…</td><td>&quot;female&quot;</td><td>null</td><td>0</td><td>&quot;146849&quot;</td><td>0.977851</td><td>null</td><td>&quot;S&quot;</td><td>1908-02-06</td><td>17:30:38</td><td>2022-08-07 20:54:02</td><td>null</td></tr><tr><td>4</td><td>&quot;Dr. Glen Woods…</td><td>&quot;male&quot;</td><td>26</td><td>0</td><td>&quot;70979&quot;</td><td>0.166117</td><td>null</td><td>&quot;S&quot;</td><td>1935-01-21</td><td>12:24:53</td><td>2022-07-30 12:50:23</td><td>null</td></tr><tr><td>5</td><td>&quot;Monica Kirby&quot;</td><td>&quot;male&quot;</td><td>null</td><td>1</td><td>&quot;57167&quot;</td><td>0.215189</td><td>null</td><td>&quot;C&quot;</td><td>1922-06-22</td><td>14:59:04</td><td>2022-07-23 14:28:38</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌─────────────┬──────────────┬────────┬──────┬───┬────────────┬────────────┬──────────────┬────────┐\n",
       "│ PassengerId ┆ Name         ┆ Sex    ┆ Age  ┆ … ┆ Birthday   ┆ Board time ┆ Married      ┆ all_NA │\n",
       "│ ---         ┆ ---          ┆ ---    ┆ ---  ┆   ┆ ---        ┆ ---        ┆ since        ┆ ---    │\n",
       "│ i64         ┆ str          ┆ cat    ┆ i64  ┆   ┆ date       ┆ time       ┆ ---          ┆ f32    │\n",
       "│             ┆              ┆        ┆      ┆   ┆            ┆            ┆ datetime[μs] ┆        │\n",
       "╞═════════════╪══════════════╪════════╪══════╪═══╪════════════╪════════════╪══════════════╪════════╡\n",
       "│ 1           ┆ Michael      ┆ male   ┆ 21   ┆ … ┆ null       ┆ 10:42:12   ┆ 2022-08-11   ┆ null   │\n",
       "│             ┆ Morales      ┆        ┆      ┆   ┆            ┆            ┆ 05:48:20     ┆        │\n",
       "│ 2           ┆ Barbara      ┆ female ┆ null ┆ … ┆ 1905-01-25 ┆ 14:27:45   ┆ 2022-07-30   ┆ null   │\n",
       "│             ┆ Curtis       ┆        ┆      ┆   ┆            ┆            ┆ 10:46:53     ┆        │\n",
       "│ 3           ┆ Kelsey       ┆ female ┆ null ┆ … ┆ 1908-02-06 ┆ 17:30:38   ┆ 2022-08-07   ┆ null   │\n",
       "│             ┆ Sanchez      ┆        ┆      ┆   ┆            ┆            ┆ 20:54:02     ┆        │\n",
       "│ 4           ┆ Dr. Glen     ┆ male   ┆ 26   ┆ … ┆ 1935-01-21 ┆ 12:24:53   ┆ 2022-07-30   ┆ null   │\n",
       "│             ┆ Woods        ┆        ┆      ┆   ┆            ┆            ┆ 12:50:23     ┆        │\n",
       "│ 5           ┆ Monica Kirby ┆ male   ┆ null ┆ … ┆ 1922-06-22 ┆ 14:59:04   ┆ 2022-07-23   ┆ null   │\n",
       "│             ┆              ┆        ┆      ┆   ┆            ┆            ┆ 14:28:38     ┆        │\n",
       "└─────────────┴──────────────┴────────┴──────┴───┴────────────┴────────────┴──────────────┴────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metasyn.distribution import DiscreteUniformDistribution\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")},\n",
    "    \"Fare\": {\"distribution\": \"LogNormalDistribution\"}, # estimate / fit an exponential distribution based on the data\n",
    "    \"Age\": {\"distribution\": DiscreteUniformDistribution(20, 40)} # fully specify a distribution for age (uniform between 20 and 40)\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897133c",
   "metadata": {},
   "source": [
    "### Specifying the distribution of structured strings\n",
    "\n",
    "For more or less structured strings, we can manually set the structure of the strings based on regular expressions. For example, we see that most Cabins are structured like [A-F] and then 2 or 3 digit numbers. We can include this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b2c4003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>i64</td><td>str</td><td>cat</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>cat</td><td>date</td><td>time</td><td>datetime[μs]</td><td>f32</td></tr></thead><tbody><tr><td>1</td><td>&quot;Michael Morale…</td><td>&quot;male&quot;</td><td>null</td><td>0</td><td>&quot;3214327&quot;</td><td>26.522736</td><td>null</td><td>&quot;C&quot;</td><td>1920-05-30</td><td>12:46:31</td><td>2022-08-08 09:00:13</td><td>null</td></tr><tr><td>2</td><td>&quot;Barbara Curtis…</td><td>&quot;male&quot;</td><td>32</td><td>0</td><td>&quot;8947447&quot;</td><td>8.91739</td><td>&quot;B608&quot;</td><td>&quot;S&quot;</td><td>1928-11-19</td><td>12:28:05</td><td>2022-08-10 14:46:09</td><td>null</td></tr><tr><td>3</td><td>&quot;Kelsey Sanchez…</td><td>&quot;male&quot;</td><td>37</td><td>0</td><td>&quot;001637&quot;</td><td>17.523508</td><td>&quot;C712&quot;</td><td>&quot;S&quot;</td><td>1931-04-04</td><td>17:31:09</td><td>2022-08-01 09:46:11</td><td>null</td></tr><tr><td>4</td><td>&quot;Dr. Glen Woods…</td><td>&quot;female&quot;</td><td>39</td><td>0</td><td>&quot;381209&quot;</td><td>45.129448</td><td>null</td><td>&quot;C&quot;</td><td>1937-04-09</td><td>14:48:35</td><td>2022-07-30 20:46:26</td><td>null</td></tr><tr><td>5</td><td>&quot;Monica Kirby&quot;</td><td>&quot;male&quot;</td><td>null</td><td>0</td><td>&quot;1789&quot;</td><td>9.833569</td><td>&quot;E972&quot;</td><td>&quot;S&quot;</td><td>1912-01-14</td><td>16:58:44</td><td>2022-07-27 22:27:21</td><td>null</td></tr><tr><td>6</td><td>&quot;Tara Riley&quot;</td><td>&quot;male&quot;</td><td>27</td><td>0</td><td>&quot;91105&quot;</td><td>41.753713</td><td>null</td><td>&quot;S&quot;</td><td>1928-12-28</td><td>18:01:01</td><td>2022-08-01 00:50:18</td><td>null</td></tr><tr><td>7</td><td>&quot;Joseph Bruce&quot;</td><td>&quot;male&quot;</td><td>32</td><td>0</td><td>&quot;652107&quot;</td><td>9.175778</td><td>null</td><td>&quot;Q&quot;</td><td>1908-12-23</td><td>14:59:54</td><td>2022-07-16 08:22:50</td><td>null</td></tr><tr><td>8</td><td>&quot;Connie Alvarez…</td><td>&quot;male&quot;</td><td>null</td><td>0</td><td>&quot;49345&quot;</td><td>57.769254</td><td>null</td><td>&quot;S&quot;</td><td>null</td><td>null</td><td>2022-07-19 23:32:34</td><td>null</td></tr><tr><td>9</td><td>&quot;Jacob Graves&quot;</td><td>&quot;male&quot;</td><td>null</td><td>1</td><td>&quot;PC 19329&quot;</td><td>38.391015</td><td>null</td><td>&quot;S&quot;</td><td>1922-09-18</td><td>18:28:51</td><td>2022-08-14 22:41:01</td><td>null</td></tr><tr><td>10</td><td>&quot;Darlene Garza&quot;</td><td>&quot;female&quot;</td><td>null</td><td>2</td><td>&quot;8931476&quot;</td><td>16.420802</td><td>&quot;D055&quot;</td><td>&quot;S&quot;</td><td>1925-12-27</td><td>14:31:39</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 13)\n",
       "┌─────────────┬──────────────┬────────┬──────┬───┬────────────┬────────────┬──────────────┬────────┐\n",
       "│ PassengerId ┆ Name         ┆ Sex    ┆ Age  ┆ … ┆ Birthday   ┆ Board time ┆ Married      ┆ all_NA │\n",
       "│ ---         ┆ ---          ┆ ---    ┆ ---  ┆   ┆ ---        ┆ ---        ┆ since        ┆ ---    │\n",
       "│ i64         ┆ str          ┆ cat    ┆ i64  ┆   ┆ date       ┆ time       ┆ ---          ┆ f32    │\n",
       "│             ┆              ┆        ┆      ┆   ┆            ┆            ┆ datetime[μs] ┆        │\n",
       "╞═════════════╪══════════════╪════════╪══════╪═══╪════════════╪════════════╪══════════════╪════════╡\n",
       "│ 1           ┆ Michael      ┆ male   ┆ null ┆ … ┆ 1920-05-30 ┆ 12:46:31   ┆ 2022-08-08   ┆ null   │\n",
       "│             ┆ Morales      ┆        ┆      ┆   ┆            ┆            ┆ 09:00:13     ┆        │\n",
       "│ 2           ┆ Barbara      ┆ male   ┆ 32   ┆ … ┆ 1928-11-19 ┆ 12:28:05   ┆ 2022-08-10   ┆ null   │\n",
       "│             ┆ Curtis       ┆        ┆      ┆   ┆            ┆            ┆ 14:46:09     ┆        │\n",
       "│ 3           ┆ Kelsey       ┆ male   ┆ 37   ┆ … ┆ 1931-04-04 ┆ 17:31:09   ┆ 2022-08-01   ┆ null   │\n",
       "│             ┆ Sanchez      ┆        ┆      ┆   ┆            ┆            ┆ 09:46:11     ┆        │\n",
       "│ 4           ┆ Dr. Glen     ┆ female ┆ 39   ┆ … ┆ 1937-04-09 ┆ 14:48:35   ┆ 2022-07-30   ┆ null   │\n",
       "│             ┆ Woods        ┆        ┆      ┆   ┆            ┆            ┆ 20:46:26     ┆        │\n",
       "│ …           ┆ …            ┆ …      ┆ …    ┆ … ┆ …          ┆ …          ┆ …            ┆ …      │\n",
       "│ 7           ┆ Joseph Bruce ┆ male   ┆ 32   ┆ … ┆ 1908-12-23 ┆ 14:59:54   ┆ 2022-07-16   ┆ null   │\n",
       "│             ┆              ┆        ┆      ┆   ┆            ┆            ┆ 08:22:50     ┆        │\n",
       "│ 8           ┆ Connie       ┆ male   ┆ null ┆ … ┆ null       ┆ null       ┆ 2022-07-19   ┆ null   │\n",
       "│             ┆ Alvarez      ┆        ┆      ┆   ┆            ┆            ┆ 23:32:34     ┆        │\n",
       "│ 9           ┆ Jacob Graves ┆ male   ┆ null ┆ … ┆ 1922-09-18 ┆ 18:28:51   ┆ 2022-08-14   ┆ null   │\n",
       "│             ┆              ┆        ┆      ┆   ┆            ┆            ┆ 22:41:01     ┆        │\n",
       "│ 10          ┆ Darlene      ┆ female ┆ null ┆ … ┆ 1925-12-27 ┆ 14:31:39   ┆ null         ┆ null   │\n",
       "│             ┆ Garza        ┆        ┆      ┆   ┆            ┆            ┆              ┆        │\n",
       "└─────────────┴──────────────┴────────┴──────┴───┴────────────┴────────────┴──────────────┴────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metasyn.distribution import RegexDistribution\n",
    "\n",
    "# To create a regex distribution, you need a list of tuples, where each tuple is an element.\n",
    "# The first part of the tuple is a string representation of the regex, while the second is the proportion of the\n",
    "# time the regex element is used.\n",
    "cabin_distribution = RegexDistribution(r\"[ABCDEF][0-9]{2,3}\")  # Add the r so that it becomes a literal string.\n",
    "# just for completeness: data generated from this distribution will always match the regex [ABCDEF]?(\\d{2,3})?\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")},\n",
    "    \"Fare\": {\"distribution\": \"ExponentialDistribution\"}, # estimate / fit an exponential distribution based on the data\n",
    "    \"Age\": {\"distribution\": DiscreteUniformDistribution(20, 40)}, # fully specify a distribution for age (uniform between 20 and 40)\n",
    "    \"Cabin\": {\"distribution\": cabin_distribution}\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93499251",
   "metadata": {},
   "source": [
    "## Comparing the final synthetic dataset to the original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2068e1d",
   "metadata": {},
   "source": [
    "Let's first compare the averages of the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a857ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>f64</td><td>str</td><td>cat</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>cat</td><td>date</td><td>time</td><td>datetime[μs]</td><td>str</td></tr></thead><tbody><tr><td>446.0</td><td>null</td><td>null</td><td>29.693277</td><td>0.381594</td><td>null</td><td>32.204208</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 13)\n",
       "┌─────────────┬──────┬──────┬───────────┬───┬──────────┬────────────┬───────────────┬────────┐\n",
       "│ PassengerId ┆ Name ┆ Sex  ┆ Age       ┆ … ┆ Birthday ┆ Board time ┆ Married since ┆ all_NA │\n",
       "│ ---         ┆ ---  ┆ ---  ┆ ---       ┆   ┆ ---      ┆ ---        ┆ ---           ┆ ---    │\n",
       "│ f64         ┆ str  ┆ cat  ┆ f64       ┆   ┆ date     ┆ time       ┆ datetime[μs]  ┆ str    │\n",
       "╞═════════════╪══════╪══════╪═══════════╪═══╪══════════╪════════════╪═══════════════╪════════╡\n",
       "│ 446.0       ┆ null ┆ null ┆ 29.693277 ┆ … ┆ null     ┆ null       ┆ null          ┆ null   │\n",
       "└─────────────┴──────┴──────┴───────────┴───┴──────────┴────────────┴───────────────┴────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ba303f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>f64</td><td>str</td><td>cat</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>cat</td><td>date</td><td>time</td><td>datetime[μs]</td><td>f32</td></tr></thead><tbody><tr><td>446.0</td><td>null</td><td>null</td><td>29.23736</td><td>0.329966</td><td>null</td><td>33.536027</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 13)\n",
       "┌─────────────┬──────┬──────┬──────────┬───┬──────────┬────────────┬───────────────┬────────┐\n",
       "│ PassengerId ┆ Name ┆ Sex  ┆ Age      ┆ … ┆ Birthday ┆ Board time ┆ Married since ┆ all_NA │\n",
       "│ ---         ┆ ---  ┆ ---  ┆ ---      ┆   ┆ ---      ┆ ---        ┆ ---           ┆ ---    │\n",
       "│ f64         ┆ str  ┆ cat  ┆ f64      ┆   ┆ date     ┆ time       ┆ datetime[μs]  ┆ f32    │\n",
       "╞═════════════╪══════╪══════╪══════════╪═══╪══════════╪════════════╪═══════════════╪════════╡\n",
       "│ 446.0       ┆ null ┆ null ┆ 29.23736 ┆ … ┆ null     ┆ null       ┆ null          ┆ null   │\n",
       "└─────────────┴──────┴──────┴──────────┴───┴──────────┴────────────┴───────────────┴────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.synthesize(len(df)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dfda1b",
   "metadata": {},
   "source": [
    "Then, we can also see how many missing values are in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ca2918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>177</td><td>0</td><td>0</td><td>0</td><td>687</td><td>2</td><td>78</td><td>79</td><td>92</td><td>891</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 13)\n",
       "┌─────────────┬──────┬─────┬─────┬───┬──────────┬────────────┬───────────────┬────────┐\n",
       "│ PassengerId ┆ Name ┆ Sex ┆ Age ┆ … ┆ Birthday ┆ Board time ┆ Married since ┆ all_NA │\n",
       "│ ---         ┆ ---  ┆ --- ┆ --- ┆   ┆ ---      ┆ ---        ┆ ---           ┆ ---    │\n",
       "│ u32         ┆ u32  ┆ u32 ┆ u32 ┆   ┆ u32      ┆ u32        ┆ u32           ┆ u32    │\n",
       "╞═════════════╪══════╪═════╪═════╪═══╪══════════╪════════════╪═══════════════╪════════╡\n",
       "│ 0           ┆ 0    ┆ 0   ┆ 177 ┆ … ┆ 78       ┆ 79         ┆ 92            ┆ 891    │\n",
       "└─────────────┴──────┴─────┴─────┴───┴──────────┴────────────┴───────────────┴────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd596fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Name</th><th>Sex</th><th>Age</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th><th>Birthday</th><th>Board time</th><th>Married since</th><th>all_NA</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>182</td><td>0</td><td>0</td><td>0</td><td>705</td><td>0</td><td>87</td><td>83</td><td>93</td><td>891</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 13)\n",
       "┌─────────────┬──────┬─────┬─────┬───┬──────────┬────────────┬───────────────┬────────┐\n",
       "│ PassengerId ┆ Name ┆ Sex ┆ Age ┆ … ┆ Birthday ┆ Board time ┆ Married since ┆ all_NA │\n",
       "│ ---         ┆ ---  ┆ --- ┆ --- ┆   ┆ ---      ┆ ---        ┆ ---           ┆ ---    │\n",
       "│ u32         ┆ u32  ┆ u32 ┆ u32 ┆   ┆ u32      ┆ u32        ┆ u32           ┆ u32    │\n",
       "╞═════════════╪══════╪═════╪═════╪═══╪══════════╪════════════╪═══════════════╪════════╡\n",
       "│ 0           ┆ 0    ┆ 0   ┆ 182 ┆ … ┆ 87       ┆ 83         ┆ 93            ┆ 891    │\n",
       "└─────────────┴──────┴─────┴─────┴───┴──────────┴────────────┴───────────────┴────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.synthesize(len(df)).null_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdb1107d616260949a63e5f4e2c5568939cf2f2c0d0d70930ae22d4d9fd1a8a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
