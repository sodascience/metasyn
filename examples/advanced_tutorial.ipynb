{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816e8dfe9a4ba016",
   "metadata": {},
   "source": [
    "# Advanced Tutorial on metasyn\n",
    "\n",
    "In this tutorial, we will be creating a `MetaFrame`, which is a metadata representation of a given dataset, and proceed by generating synthetic data from it. In the process, we are going to walk through some of the advanced abilities of metasyn, such as handling dates, setting distributions and ensuring uniqueness in columns. This example workflow starts from a `.csv` file as input, but it easily adapted to other formats. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6597b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 0: Install the metasyn package and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line and run the cell to install metasyn\n",
    "# %pip install metasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import datetime as dt\n",
    "import polars as pl\n",
    "from metasyn import MetaFrame, demo_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04466c26",
   "metadata": {},
   "source": [
    "## Step 1: Transforming your data into a polars DataFrame\n",
    "\n",
    "The first step in creating the MetaFrame is reading and converting your dataset to a polars DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path of the demo csv\n",
    "demo_file_path = demo_file()\n",
    "\n",
    "# read the data with the correct categorical variables\n",
    "data_types={\n",
    "    \"Sex\": pl.Categorical,\n",
    "    \"Embarked\": pl.Categorical\n",
    "}\n",
    "\n",
    "df = pl.read_csv(demo_file_path, try_parse_dates=True, dtypes=data_types)\n",
    "\n",
    "# check out the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2481d4",
   "metadata": {},
   "source": [
    "Now, let's check the data types of our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(df.columns, df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebde17e",
   "metadata": {},
   "source": [
    "We see that most variables are now nicely specified as strings, categories, dates and ints where necessary. We can also inspect the data a bit more with `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c2acb55fca193",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3f1e974e84da4",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13f849ed",
   "metadata": {},
   "source": [
    "## Step 2: Creating a MetaFrame object from a DataFrame\n",
    "\n",
    "Now that we have properly formatted our DataFrame, we can easily generate a MetaFrame for it. For now we'll do this using the default settings (i.e. without specifying any optional parameters). \n",
    "\n",
    "> **MetaFrames:**\n",
    "> A **MetaFrame** is an object which captures the essential aspects of the dataset, including variable names, types, data types, the percentage of missing values, and distribution attributes. MetaFrame objects capture all the information needed to generate a synthetic dataset that aligns with the original dataset, without containing any *entries* of the original dataset.\n",
    "\n",
    "More information on generating MetaFrames can be found on the metasyn docs, [here](https://metasynth.readthedocs.io/en/latest/usage/generating_metaframes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c58473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MetaFrame.fit_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a772d",
   "metadata": {},
   "source": [
    "We can call the `print` function to display the (statistical metadata contained in the) MetaFrame in an easy-to-read format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b27a95",
   "metadata": {},
   "source": [
    "## Step 3: Exporting the MetaFrame\n",
    "\n",
    "After creating the MetaFrame, Metasyn can serialize and export it into a GMF file using `mf.export()`, passing in the filepath as a parameter. \n",
    "\n",
    "\n",
    "> **GMF files:**\n",
    "> GMF files are JSON files that follow the [Generative Metadata Format (GMF)](https://github.com/sodascience/generative_metadata_format), a format designed to contain statistical metadata for (tabular) datasets that has been designed to be easy to read and understand. This allows users to audit, understand, modify and share their data generation model with ease.\n",
    "\n",
    "More information on exporting and importing MetaFrames can be found on the metasyn docs, [here](https://metasynth.readthedocs.io/en/latest/usage/exporting_metaframes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e355f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"example_gmf_titanic.json\"\n",
    "\n",
    "# Serialize and export the MetaFrame to a GMF file\n",
    "mf.export(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can now open and read the GMF formatted .json file!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a79120f6b907d352"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you'd like to preview how the exported file would look, without saving it to disk, this can be done by using the `repr` function as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fea40d1407e42ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gmf_preview = repr(mf)\n",
    "print(gmf_preview)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b72d8907ec04999"
  },
  {
   "cell_type": "markdown",
   "id": "fcd16a5a",
   "metadata": {},
   "source": [
    "A (previously exported) GMF file can be imported and loaded into a MetaFrame using the `MetaFrame.from_json()` class method, passing in the file path as a parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eac7eeb3326f03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a MetaFrame based on a GMF (.json) file\n",
    "mf = MetaFrame.from_json(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Generating synthetic data from a MetaFrame"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6571873d"
  },
  {
   "cell_type": "markdown",
   "id": "85201666a67a73fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Once a MetaFrame is loaded, synthetic data can be generated from it. The `synthesize` method takes the number of rows to be generated as parameter and returns a DataFrame with the synthetic data.\n",
    "\n",
    "More information on generating synthetic data based on MetaFrames can be found on the metasyn docs, [here](https://metasynth.readthedocs.io/en/latest/usage/generating_synthetic_data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b1e95",
   "metadata": {},
   "source": [
    "As you can see, the fake data looks a lot like the real data! However, it could still use some improvement. In the next sections, we will explore manual changes we can make to improve the quality of the synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cfe6cd",
   "metadata": {},
   "source": [
    "## Step 5: Improving the quality of the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32cc3a",
   "metadata": {},
   "source": [
    "### Set unique columns\n",
    "\n",
    "One column (PassengerId) has been detected as possibly unique by metasyn, as indicated by the following warning:\n",
    "\n",
    "> \"Variable PassengerId seems unique, but not set to be unique.\"\n",
    "\n",
    "This column holds a variable with unique passenger identifiers, so in fact we do want synthetic data generated for this column to be unique as well. We can add this to the metadata by creating a list of options which we call a `specification`, or `spec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b76751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a specification dictionary for the variables\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}\n",
    "}\n",
    "\n",
    "# then, we add that dictionary as the `spec` argument\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "\n",
    "# then, let's check what the metadata about PassengerId contains!\n",
    "mf[\"PassengerId\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f0970",
   "metadata": {},
   "source": [
    "So let's check what is generated from this new MetaFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7f562",
   "metadata": {},
   "source": [
    "Now we that the `PassengerId` column is correctly represented with increasing id numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f884eb7",
   "metadata": {},
   "source": [
    "### Fake names (and others)\n",
    "\n",
    "As one can see, the `Name` of the passengers is not quite so well synthesized. The reason is that the string type interpreter in metasyn is designed for `structured` strings (like room numbers such as `B1.09`, `B1.01` or `A1.08`) and not unstructured strings. However, metasyn supports the [faker](https://faker.readthedocs.io/en/master/index.html) package, which includes a lot of data types that it can fake. The columns using faker are not based on the real data at all so they do not disclose any info about the real data.\n",
    "\n",
    "We fake names as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5615aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a specification dictionary for the variables\n",
    "from metasyn.distribution import FakerDistribution\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")}\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1fa66b",
   "metadata": {},
   "source": [
    "That already looks a lot better for the `Name` column!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set distributions manually\n",
    "\n",
    "Without user input, the distribution chosen for each variable is inferred by choosing the best fitting from available distributions for the variable type. However, we can also manually specify which distribution to fit, or we can even just fully specify how the variable should be generated."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1b8b5b434fe1f52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ba506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metasyn.distribution import DiscreteUniformDistribution\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")},\n",
    "    \"Fare\": {\"distribution\": \"LogNormalDistribution\"}, # estimate / fit an exponential distribution based on the data\n",
    "    \"Age\": {\"distribution\": DiscreteUniformDistribution(20, 40)} # fully specify a distribution for age (uniform between 20 and 40)\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897133c",
   "metadata": {},
   "source": [
    "### Specifying the distribution of structured strings\n",
    "\n",
    "For more or less structured strings, we can manually set the structure of the strings based on regular expressions. For example, we see that most Cabins are structured like [A-F] and then 2 or 3 digit numbers. We can include this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c4003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metasyn.distribution import RegexDistribution\n",
    "\n",
    "# To create a regex distribution, you need a list of tuples, where each tuple is an element.\n",
    "# The first part of the tuple is a string representation of the regex, while the second is the proportion of the\n",
    "# time the regex element is used.\n",
    "cabin_distribution = RegexDistribution(r\"[ABCDEF][0-9]{2,3}\")  # Add the r so that it becomes a literal string.\n",
    "# just for completeness: data generated from this distribution will always match the regex [ABCDEF]?(\\d{2,3})?\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")},\n",
    "    \"Fare\": {\"distribution\": \"ExponentialDistribution\"}, # estimate / fit an exponential distribution based on the data\n",
    "    \"Age\": {\"distribution\": DiscreteUniformDistribution(20, 40)}, # fully specify a distribution for age (uniform between 20 and 40)\n",
    "    \"Cabin\": {\"distribution\": cabin_distribution}\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93499251",
   "metadata": {},
   "source": [
    "## Step 6: Comparing the final synthetic dataset to the original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2068e1d",
   "metadata": {},
   "source": [
    "Let's first compare the averages of the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba303f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(len(df)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dfda1b",
   "metadata": {},
   "source": [
    "Then, we can also see how many missing values are in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd596fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(len(df)).null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 7: Adding descriptions to variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ab5b2b2c56065b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the data being taken care of, we can still do one last thing. We can add descriptions to the variables, to clarify what they mean. This can be particularly useful when sharing the `MetaFrame` or generated data with others, as it gives them more context to what they're working with.\n",
    "\n",
    "It is possible to specify a description for each variable. This can be done by adding a `description` key to the specification dictionary of a variable,  before creating a `MetaFrame`. For example, adding a description to the `Cabin` column can be done as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27bc0135d1eebc38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")},\n",
    "    \"Fare\": {\"distribution\": \"ExponentialDistribution\"}, # estimate / fit an exponential distribution based on the data\n",
    "    \"Age\": {\"distribution\": DiscreteUniformDistribution(20, 40)}, # fully specify a distribution for age (uniform between 20 and 40)\n",
    "    \"Cabin\": {\"distribution\": cabin_distribution, \"description\": \"The cabin number of the passenger.\"},\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e37faad4df8ffde8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can get a list of all the descriptions in the fitted `MetaFrame` by accessing its `descriptions` property, as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b4bd251795308d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(mf.descriptions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "694d4474707f7950"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instead of setting the description in the variable specification (which happens before fitting a `MetaFrame` to a `DataFrame`), we can assign a description to an already generated `MetaFrame` by directly setting a column's description attribute. For example, we can assign a description to the `PassengerId` column as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8411571bf1e5bf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mf[\"PassengerId\"].description = \"The ID of each passenger, as assigned by Pandas.\"\n",
    "\n",
    "print(mf.descriptions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34a8aafc95c0219f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also set multiple descriptions of an already generated `MetaFrame` at once by passing in a dictionary of descriptions to its `descriptions` property. For example, we can set descriptions for the `Age` and `Name` columns as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bf1c3ad724c9bfa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mf.descriptions = {\"Name\": \"Name of the passenger\", \"Age\": \"Age of the passenger in years\"}\n",
    "\n",
    "print(mf.descriptions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b2e873f7362160a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instead of a dictionary, it is also possible to pass in a list of descriptions to the `descriptions` property of a `MetaFrame`. \n",
    "\n",
    "This can only be done if the list has the same length as the number of variables. In other words, each description must be passed in. \n",
    "\n",
    "This can be useful for example when generating placeholder descriptions automatically through list comprehension, as is done in the following example:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcf3b9eb9bbf6b17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mf.descriptions = [f\"Placeholder description for {var.name}\" for var in mf.meta_vars]\n",
    "\n",
    "print(mf.descriptions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab2b34ed6b11578c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdb1107d616260949a63e5f4e2c5568939cf2f2c0d0d70930ae22d4d9fd1a8a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
