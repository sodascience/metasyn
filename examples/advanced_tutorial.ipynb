{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816e8dfe9a4ba016",
   "metadata": {},
   "source": [
    "# Advanced Tutorial on MetaSynth\n",
    "\n",
    "In this tutorial, we will be creating a `MetaFrame`, which is a metadata representation of a given dataset, and proceed by generating synthetic data from it. In the process, we are going to walk through some of the advanced abilities of MetaSynth, such as handling dates, setting distributions and ensuring uniqueness in columns. This example workflow starts from a `.csv` file as input, but it easily adapted to other formats. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6597b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 0: Install the metasynth package and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line and run the cell to install metasynth\n",
    "# %pip install metasynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import datetime as dt\n",
    "import polars as pl\n",
    "from metasynth import MetaFrame, demo_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04466c26",
   "metadata": {},
   "source": [
    "## Step 1: Transforming your data into a polars DataFrame\n",
    "\n",
    "The first step in creating the MetaFrame is reading and converting your dataset to a polars DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path of the demo csv\n",
    "demo_file_path = demo_file()\n",
    "\n",
    "# read the data with the correct categorical variables\n",
    "data_types={\n",
    "    \"Sex\": pl.Categorical,\n",
    "    \"Embarked\": pl.Categorical\n",
    "}\n",
    "\n",
    "df = pl.read_csv(demo_file_path, try_parse_dates=True, dtypes=data_types)\n",
    "\n",
    "# check out the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2481d4",
   "metadata": {},
   "source": [
    "Now, let's check the data types of our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(df.columns, df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebde17e",
   "metadata": {},
   "source": [
    "We see that most variables are now nicely specified as strings, categories, dates and ints where necessary. We can also inspect the data a bit more with `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c2acb55fca193",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3f1e974e84da4",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13f849ed",
   "metadata": {},
   "source": [
    "## Step 2: Creating a MetaFrame object from a DataFrame\n",
    "\n",
    "Now a lot of work has already gone into creating a properly formatted DataFrame. This work pays off at this stage: let's convert the DataFrame to a MetaFrame structure with the default options. Note: this takes a little bit of time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c58473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MetaFrame.fit_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a772d",
   "metadata": {},
   "source": [
    "Then, we can simply print the MetaFrame to display it in an easy-to-read format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3edae1eedf4b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Alternatively, we can preview the MetaFrame as it would be output to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6f59f1d439189",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_preview = repr(mf)\n",
    "print(json_preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b27a95",
   "metadata": {},
   "source": [
    "## Step 3: Saving the metadata in a file\n",
    "\n",
    "After creating the MetaFrame, we can save it to a file. The default format is `JSON`, which is both easy to read for humans and computers. This allows one to manually inspect the metadata file and verify no sensitive information would be shared. If the disclosure risk is deemed low, the JSON file can then be securely provided to others for exploratory analysis or other uses without exposing private data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e355f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the metadata to a file\n",
    "file_path = \"demonstration_metadata.json\"\n",
    "mf.to_json(file_path)\n",
    "\n",
    "# you can now open and read the json file!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571873d",
   "metadata": {},
   "source": [
    "## Step 4: Generating synthetic data from the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd16a5a",
   "metadata": {},
   "source": [
    "A previously exported MetaFrame (.json) file can be loaded into a MetaFrame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eac7eeb3326f03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load previously exported MetaFrame (.json) file\n",
    "mf = MetaFrame.from_json(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85201666a67a73fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Once a MetaFrame is loaded, synthetic data can be generated from it. The `synthesize` method takes the number of rows to be generated as parameter and returns a DataFrame with the synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b1e95",
   "metadata": {},
   "source": [
    "As you can see, the fake data looks a lot like the real data! However, it could still use some improvement. In the next sections, we will explore manual changes we can make to improve the quality of the synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cfe6cd",
   "metadata": {},
   "source": [
    "## Step 5: Improving the quality of the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32cc3a",
   "metadata": {},
   "source": [
    "### Set unique columns\n",
    "\n",
    "One column (PassengerId) has been detected as possibly unique by MetaSynth, as indicated by the following warning:\n",
    "\n",
    "> \"Variable PassengerId seems unique, but not set to be unique.\"\n",
    "\n",
    "This column holds a variable with unique passenger identifiers, so in fact we do want synthetic data generated for this column to be unique as well. We can add this to the metadata by creating a list of options which we call a `specification`, or `spec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b76751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a specification dictionary for the variables\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}\n",
    "}\n",
    "\n",
    "# then, we add that dictionary as the `spec` argument\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "\n",
    "# then, let's check what the metadata about PassengerId contains!\n",
    "mf[\"PassengerId\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f0970",
   "metadata": {},
   "source": [
    "So let's check what is generated from this new MetaFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7f562",
   "metadata": {},
   "source": [
    "Now we that the `PassengerId` column is correctly represented with increasing id numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f884eb7",
   "metadata": {},
   "source": [
    "### Fake names (and others)\n",
    "\n",
    "As one can see, the `Name` of the passengers is not quite so well synthesized. The reason is that the string type interpreter in MetaSynth is designed for `structured` strings (like room numbers such as `B1.09`, `B1.01` or `A1.08`) and not unstructured strings. However, MetaSynth supports the [faker](https://faker.readthedocs.io/en/master/index.html) package, which includes a lot of data types that it can fake. The columns using faker are not based on the real data at all so they do not disclose any info about the real data.\n",
    "\n",
    "We fake names as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5615aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a specification dictionary for the variables\n",
    "from metasynth.distribution import FakerDistribution\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")}\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1fa66b",
   "metadata": {},
   "source": [
    "That already looks a lot better for the `Name` column!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf927af6",
   "metadata": {},
   "source": [
    "### Set distributions manually\n",
    "\n",
    "Without user input, the distribution chosen for each variable is inferred by choosing the best fitting from available distributions for the variable type. However, we can also manually specify which distribution to fit, or we can even just fully specify how the variable should be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ba506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metasynth.distribution import DiscreteUniformDistribution\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")},\n",
    "    \"Fare\": {\"distribution\": \"LogNormalDistribution\"}, # estimate / fit an exponential distribution based on the data\n",
    "    \"Age\": {\"distribution\": DiscreteUniformDistribution(20, 40)} # fully specify a distribution for age (uniform between 20 and 40)\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897133c",
   "metadata": {},
   "source": [
    "### Specifying the distribution of structured strings\n",
    "\n",
    "For more or less structured strings, we can manually set the structure of the strings based on regular expressions. For example, we see that most Cabins are structured like [A-F] and then 2 or 3 digit numbers. We can include this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c4003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metasynth.distribution import RegexDistribution\n",
    "\n",
    "# To create a regex distribution, you need a list of tuples, where each tuple is an element.\n",
    "# The first part of the tuple is a string representation of the regex, while the second is the proportion of the\n",
    "# time the regex element is used.\n",
    "cabin_distribution = RegexDistribution(r\"[ABCDEF][0-9]{2,3}\")  # Add the r so that it becomes a literal string.\n",
    "# just for completeness: data generated from this distribution will always match the regex [ABCDEF]?(\\d{2,3})?\n",
    "\n",
    "var_spec = {\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")},\n",
    "    \"Fare\": {\"distribution\": \"ExponentialDistribution\"}, # estimate / fit an exponential distribution based on the data\n",
    "    \"Age\": {\"distribution\": DiscreteUniformDistribution(20, 40)}, # fully specify a distribution for age (uniform between 20 and 40)\n",
    "    \"Cabin\": {\"distribution\": cabin_distribution}\n",
    "}\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "mf.synthesize(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93499251",
   "metadata": {},
   "source": [
    "## Comparing the final synthetic dataset to the original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2068e1d",
   "metadata": {},
   "source": [
    "Let's first compare the averages of the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba303f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(len(df)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dfda1b",
   "metadata": {},
   "source": [
    "Then, we can also see how many missing values are in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd596fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(len(df)).null_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdb1107d616260949a63e5f4e2c5568939cf2f2c0d0d70930ae22d4d9fd1a8a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
