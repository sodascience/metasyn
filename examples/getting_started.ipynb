{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c6597b",
   "metadata": {},
   "source": [
    "# Getting started with MetaSynth\n",
    "\n",
    "In this tutorial, we will be creating a `generative metadata format` (`gmf`) metadata file from a dataset using MetaSynth, and then we will generate synthetic data from it. This example workflow starts from a `.csv` file as input, but it easily adapted to other formats. \n",
    "\n",
    "First, install the metasynth package in your session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line and run the cell to install metasynth\n",
    "# %pip install metasynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import datetime as dt\n",
    "import polars as pl\n",
    "from metasynth import MetaFrame, demo_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04466c26",
   "metadata": {},
   "source": [
    "## Step 1: Load the data into a data frame\n",
    "\n",
    "The first step in creating the metadata is reading and converting your dataset to a DataFrame with the correct data types. We use the [polars](https://pola.rs) dataframe library for this (but you could also use pandas!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path of the demo csv\n",
    "demo_file_path = demo_file()\n",
    "\n",
    "# read the data with the correct categorical variables\n",
    "demo_types={\n",
    "    \"Sex\": pl.Categorical,\n",
    "    \"Embarked\": pl.Categorical\n",
    "}\n",
    "df = pl.read_csv(demo_file_path, try_parse_dates=True, dtypes=demo_types)\n",
    "\n",
    "# check out the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2481d4",
   "metadata": {},
   "source": [
    "Now, let's check the data types of our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(df.columns, df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebde17e",
   "metadata": {},
   "source": [
    "We see that most variables are now nicely specified as strings, categories, dates and ints where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d608127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also inspect the data a bit more with describe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f849ed",
   "metadata": {},
   "source": [
    "## Step 2: Creating a MetaFrame object from a DataFrame\n",
    "\n",
    "Now a lot of work has already gone into creating a properly formatted dataframe. This work pays off at this stage: let's convert the DataFrame to a meta_dataset structure with the default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c58473",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset = MetaFrame.fit_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a772d",
   "metadata": {},
   "source": [
    "Then, we can show the metadata as a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b27a95",
   "metadata": {},
   "source": [
    "## Step 3: Saving the metadata in a file\n",
    "\n",
    "After creating the metadata, we can save it to a file. The default format is `json`, meaning the file is quite legible by humans and computers alike. Therefore, it can be checked by the data controller and, when the disclosure risk is deemed to be low, this file can be shared with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e355f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"demonstration_metadata.json\"\n",
    "meta_dataset.to_json(file_path)\n",
    "\n",
    "# you can now open and read the json file!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571873d",
   "metadata": {},
   "source": [
    "## Step 4: Generating synthetic data from the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd16a5a",
   "metadata": {},
   "source": [
    "Upon receiving this file, you can use the MetaSynth package to generate a synthetic version of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_meta_dataset = MetaFrame.from_json(file_path)\n",
    "new_meta_dataset.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b1e95",
   "metadata": {},
   "source": [
    "As you can see, the fake data looks a lot like the real data! However, it could still use some improvement. Below, we create this metadata with additional manual improvements. If you want to know more about these improvements, take a look at our [advanced tutorial](https://colab.research.google.com/github/sodascience/metasynth/blob/main/examples/advanced_tutorial.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ba506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metasynth.distribution import DiscreteUniformDistribution, RegexDistribution, FakerDistribution\n",
    "\n",
    "# Using some advanced features of metasynth\n",
    "var_spec = {\n",
    "    # Ensure that the passengerId column is unique\n",
    "    \"PassengerId\": {\"unique\": True}, \n",
    "    # Use fake names for the name column\n",
    "    \"Name\": {\"distribution\": FakerDistribution(\"name\")}, \n",
    "     # Estimate / fit an exponential distribution\n",
    "    \"Fare\": {\"distribution\": \"LogNormalDistribution\"},\n",
    "    # Manually set a distribution for age \n",
    "    \"Age\": {\"distribution\": DiscreteUniformDistribution(20, 40)},\n",
    "    # Manually set a regex distribution for cabin\n",
    "    \"Cabin\": {\"distribution\": RegexDistribution(r\"[ABCDEF]\\d{2,3}\")}\n",
    "}\n",
    "\n",
    "# create the high-quality metadata\n",
    "meta_dataset = MetaFrame.fit_dataframe(df, spec=var_spec)\n",
    "\n",
    "# generate synthetic data\n",
    "syn_df = meta_dataset.synthesize(len(df))\n",
    "syn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2068e1d",
   "metadata": {},
   "source": [
    "Now, let's compare the synthetic data to the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba303f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdb1107d616260949a63e5f4e2c5568939cf2f2c0d0d70930ae22d4d9fd1a8a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
