{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816e8dfe9a4ba016",
   "metadata": {},
   "source": [
    "# Advanced Tutorial on metasyn\n",
    "\n",
    "In this tutorial, we will be creating synthetic data using the `metasyn` package.\n",
    "\n",
    "Some advanced features of metasyn will be covered further along the tutorial, such as handling dates, setting distributions, ensuring uniqueness in columns and adding variable descriptions.\n",
    "\n",
    "For more information refer to the [user's guide](https://metasynth.readthedocs.io/en/latest/usage/usage.html) on the docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6597b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 0: Install the metasyn package and import required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce44185723aaacd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, let's install the metasyn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following line to install metasyn\n",
    "# %pip install metasyn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abb192e714247c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, let's import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import polars as pl\n",
    "\n",
    "from metasyn import MetaFrame, demo_file\n",
    "from metasyn.config import VarConfig\n",
    "from metasyn.util import DistributionSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04466c26",
   "metadata": {},
   "source": [
    "## Step 1: Loading the dataset\n",
    "\n",
    "The first step to create synthetic data is to load your dataset into a DataFrame. For this tutorial, we will be using the [Titanic dataset](https://www.kaggle.com/c/titanic/data), which can easily be accessed through the metasyn `demo_file()` function. \n",
    "\n",
    "It is important to set the data types of columns in the DataFrame correctly, as this will help metasyn to infer the correct distributions for each variable later.\n",
    "\n",
    "\n",
    "> **Note** \n",
    "> In this tutorial we use [Polars](https://pola.rs) to create the DataFrame, as that is what metasyn uses internally. Pandas is also supported, but will automatically be converted to Polars by metasyn. For best results it is recommended to use Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path of the demo csv\n",
    "demo_file_path = demo_file()\n",
    "\n",
    "# read the data with the correct categorical variables\n",
    "data_types={\n",
    "    \"Sex\": pl.Categorical,\n",
    "    \"Embarked\": pl.Categorical\n",
    "}\n",
    "\n",
    "# create the DataFrame\n",
    "df = pl.read_csv(demo_file_path, try_parse_dates=True, dtypes=data_types)\n",
    "\n",
    "# check out the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2481d4",
   "metadata": {},
   "source": [
    "We can check the data types of our DataFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(df.columns, df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebde17e",
   "metadata": {},
   "source": [
    "We see that most variables are now nicely specified as strings, categories, dates and ints where necessary. We can get some more information on the DataFrame by calling the `describe()` on it, this will give us some information on the distribution of the variables:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c2acb55fca193",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f849ed",
   "metadata": {},
   "source": [
    "## Step 2: Generating a MetaFrame\n",
    "\n",
    "Now that we have properly formatted our DataFrame, we can easily generate a MetaFrame for it. \n",
    "We'll do this without passing in any optional parameters, but later on in this tutorial we will cover how custom parameters can help provide control over the MetaFrame generation process. \n",
    "\n",
    "> **MetaFrames:**\n",
    "> A MetaFrame is an object which captures the essential aspects of the dataset, including variable names, types, data types, the percentage of missing values, and distribution parameters. MetaFrame objects capture all the information needed to generate a synthetic dataset that aligns with the original dataset, without containing any *entries* of the original dataset.\n",
    "\n",
    "More information on generating MetaFrames can be found on the metasyn docs ['generating metaframes'](https://metasynth.readthedocs.io/en/latest/usage/generating_metaframes.html) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5d2759a1381f1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Generating a MetaFrame is simple, and can be done by simply calling the `MetaFrame.fit_dataframe()` class method, passing in the DataFrame as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c58473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and fit a MetaFrame to the DataFrame \n",
    "mf = MetaFrame.fit_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a772d",
   "metadata": {},
   "source": [
    "We can use the built-in Python `print` function to display the (statistical) metadata contained in the MetaFrame in an easy-to-read format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b27a95",
   "metadata": {},
   "source": [
    "## Step 3: Exporting the MetaFrame\n",
    "\n",
    "After creating the MetaFrame, Metasyn can serialize and export it into a GMF file using `mf.export()`, passing in the filepath as a parameter. \n",
    "\n",
    "\n",
    "> **GMF files:**\n",
    "> GMF files are JSON files that follow the [Generative Metadata Format (GMF)](https://github.com/sodascience/generative_metadata_format), a format designed to contain statistical metadata for (tabular) datasets that has been designed to be easy to read and understand. This allows users to audit, understand, modify and share their data generation model with ease.\n",
    "\n",
    "More information on exporting and importing MetaFrames can be found on the metasyn docs ['exporting and importing metaframes'](https://metasynth.readthedocs.io/en/latest/usage/exporting_metaframes.html) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e355f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"example_gmf_titanic.json\"\n",
    "\n",
    "# Serialize and export the MetaFrame to a GMF file\n",
    "mf.export(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79120f6b907d352",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The GMF file should now be saved to the specified filepath, feel free to open and inspect it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea40d1407e42ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It's also possible to preview how the exported file would look, without actually saving it to disk. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b72d8907ec04999",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a preview of the GMF file (`repr()`) and print it (`print()`)\n",
    "print(repr(mf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd16a5a",
   "metadata": {},
   "source": [
    "A GMF file can be imported and loaded into a MetaFrame using the `MetaFrame.from_json()` class method, passing in the file path as a parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eac7eeb3326f03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a MetaFrame based on a GMF (.json) file\n",
    "mf = MetaFrame.from_json(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571873d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4: Generating synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85201666a67a73fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Once a MetaFrame is loaded, synthetic data can be generated from it. We can do so by using the the `synthesize` method of the MetaFrame, passing in how many rows the generated data should contain as a parameter. This returns a DataFrame with the synthetic data.\n",
    "\n",
    "More information on generating synthetic data based on MetaFrames can be found on the metasyn docs, [here](https://metasynth.readthedocs.io/en/latest/usage/generating_synthetic_data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "syn_df = mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565073e9dc5ebcc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can now view the synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39faa852ccdd5ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b1e95",
   "metadata": {},
   "source": [
    "As you can see, the synthetic data looks a lot like the real data! However, it could still use some improvement. In the next sections, we will explore manual changes we can make to improve the quality of the synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cfe6cd",
   "metadata": {},
   "source": [
    "## Step 5: Improving the quality of the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77224c9e212c06",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The `MetaFrame.fit_dataframe()` method allows you to have more control over how your synthetic dataset is generated by passing in an optional `spec` (short for specification) parameter. `spec` is a dictionary that can be used to give metasyn instructions on a per-variable basis, these instructions can range from setting a variable to be unique, to directly setting its distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32cc3a",
   "metadata": {},
   "source": [
    "### Spec: Setting variables to have unique variables\n",
    "\n",
    "During the MetaFrame generation at the start (using `MetaFrame.fit_dataframe()`), metaframe detected a column (PassengerId) as possibly unique, as indicated by the following warning:\n",
    "\n",
    "> *\"Variable PassengerId seems unique, but not set to be unique.\"*\n",
    "\n",
    "This is because this column holds a unique identifier for each passenger, which is in fact unique to each passenger. As such, we want the synthetic data generated for this column to be unique as well. \n",
    "\n",
    "In order to set a variable to be unique, we can add a `unique` key to the specification dictionary of the variable, and set it to `True`. We can do it for the `PassengerId` column as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b76751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a specification dictionary for the variables\n",
    "var_spec = [VarConfig(name=\"PassengerId\", dist_spec=DistributionSpec(unique=True))]\n",
    "\n",
    "# then, we add that dictionary as the `spec` argument\n",
    "mf = MetaFrame.fit_dataframe(df, var_specs=var_spec)\n",
    "\n",
    "# then, let's check what the metadata about PassengerId contains!\n",
    "mf[\"PassengerId\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f0970",
   "metadata": {},
   "source": [
    "So let's check what is generated from this new MetaFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7f562",
   "metadata": {},
   "source": [
    "As you can see, the `PassengerId` column is now unique!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f884eb7",
   "metadata": {},
   "source": [
    "### Spec: Fake names (and other Faker data types)\n",
    "\n",
    "Currently, the `Name` of the passengers is not quite so well synthesized. The reason is that the string type interpreter in metasyn is designed for `structured` strings (like room numbers such as `B1.09`, `B1.01` or `A1.08`) and not unstructured strings. However, metasyn supports the [faker](https://faker.readthedocs.io/en/master/index.html) package, which includes a lot of data types that it can fake. The columns using faker are not based on the real data at all so they do not disclose any info about the real data.\n",
    "\n",
    "We can specify metasyn to use Faker names for the `Name` column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5615aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a specification dictionary for the variables\n",
    "from metasyn.distribution import FakerDistribution\n",
    "\n",
    "var_specs = [\n",
    "    VarConfig(name=\"PassengerId\", dist_spec=DistributionSpec(unique=True)),\n",
    "    VarConfig(name=\"Name\", dist_spec=FakerDistribution(\"name\")),\n",
    "]\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, var_specs=var_specs)\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1fa66b",
   "metadata": {},
   "source": [
    "That already looks a lot better for the `Name` column!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8b5b434fe1f52",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Spec: Setting distributions manually\n",
    "\n",
    "Without user input, the distribution chosen for each variable is inferred by choosing the distribution with the best fit from all available distributions for the variable type. However, we can also manually specify which distribution to fit, or simply specify the distribution including the parameters for the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ba506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metasyn.distribution import DiscreteUniformDistribution\n",
    "\n",
    "var_specs = [\n",
    "    VarConfig(name=\"PassengerId\", dist_spec=DistributionSpec(unique=True)),\n",
    "    VarConfig(name=\"Name\", dist_spec=FakerDistribution(\"name\")),\n",
    "    VarConfig(name=\"Name\", dist_spec=\"LogNormalDistribution\"), # estimate / fit an exponential distribution based on the data\n",
    "    VarConfig(name=\"Age\", dist_spec=DiscreteUniformDistribution(20, 40)) # fully specify a distribution for age (uniform between 20 and 40)\n",
    "]\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, var_specs=var_specs)\n",
    "mf.synthesize(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897133c",
   "metadata": {},
   "source": [
    "### Spec: Specifying the distribution of structured strings\n",
    "\n",
    "For more or less structured strings, we can manually set the structure of the strings based on regular expressions. For example, we see that most Cabins are structured like [A-F] and then 2 or 3 digit numbers. We can include this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c4003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metasyn.distribution import RegexDistribution\n",
    "\n",
    "# To create a regex distribution, you need a list of tuples, where each tuple is an element.\n",
    "# The first part of the tuple is a string representation of the regex, while the second is the proportion of the\n",
    "# time the regex element is used.\n",
    "cabin_distribution = RegexDistribution(r\"[A-F][0-9]{2,3}\")  # Add the r so that it becomes a literal string.\n",
    "# just for completeness: data generated from this distribution will always match the regex [A-F]?(\\d{2,3})?\n",
    "\n",
    "var_specs = [\n",
    "    VarConfig(name=\"PassengerId\", dist_spec=DistributionSpec(unique=True)),\n",
    "    VarConfig(name=\"Name\", dist_spec=FakerDistribution(\"name\")),\n",
    "    VarConfig(name=\"Name\", dist_spec=\"LogNormalDistribution\"), # estimate / fit an exponential distribution based on the data\n",
    "    VarConfig(name=\"Age\", dist_spec=DiscreteUniformDistribution(20, 40)), # fully specify a distribution for age (uniform between 20 and 40)\n",
    "    VarConfig(name=\"Cabin\", dist_spec=cabin_distribution), # Use the regex distribution for the cabin\n",
    "]\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, var_specs=var_specs)\n",
    "mf.synthesize(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93499251",
   "metadata": {},
   "source": [
    "## Step 6: Comparing the final synthetic dataset to the original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2068e1d",
   "metadata": {},
   "source": [
    "Let's first compare the averages of the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba303f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(len(df)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dfda1b",
   "metadata": {},
   "source": [
    "Then, we can also see how many missing values are in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd596fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.synthesize(len(df)).null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5b2b2c56065b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 7: Adding descriptions to variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc0135d1eebc38",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With the data being taken care of, we can still do one last thing. We can add descriptions to the variables, to clarify what they mean. This can be particularly useful when sharing the `MetaFrame` or generated data with others, as it gives them more context to what they're working with.\n",
    "\n",
    "One way of adding a description to a variable, is by setting it in the `spec` dictionary, this can be done by simply adding a `description` key with the description as a value. For example, adding a description to the `Cabin` column can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37faad4df8ffde8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_specs = [\n",
    "    # Ensure unique values for the `PassengerId` column\n",
    "    VarConfig(name=\"PassengerId\", dist_spec=DistributionSpec(unique=True)),\n",
    "\n",
    "    # Utilize the Faker library to synthesize realistic names for the `Name` column\n",
    "    VarConfig(name=\"Name\", dist_spec=FakerDistribution(\"name\")),\n",
    "\n",
    "    # Fit `Fare` to an log-normal distribution, but base the parameters on the data\n",
    "    VarConfig(name=\"Name\", dist_spec=\"LogNormalDistribution\"),\n",
    "\n",
    "    # Set the `Age` column to a discrete uniform distribution ranging from 20 to 40\n",
    "    VarConfig(name=\"Age\", dist_spec=DiscreteUniformDistribution(20, 40)),\n",
    "\n",
    "    # Use a regex-based distribution to generate `Cabin` values following [A-F][0-9]{2,3}\n",
    "    VarConfig(name=\"Cabin\", dist_spec=cabin_distribution, description=\"The cabin number of the passenger.\"),\n",
    "]\n",
    "\n",
    "mf = MetaFrame.fit_dataframe(df, var_specs=var_specs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4bd251795308d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can get a list of all the descriptions in the fitted `MetaFrame` by accessing its `descriptions` property, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d4474707f7950",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mf.descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8411571bf1e5bf7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Instead of setting the description in the variable specification (which happens before fitting a `MetaFrame` to a `DataFrame`), we can assign a description to an already generated `MetaFrame` by directly setting a column's description attribute. For example, we can assign a description to the `PassengerId` column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8aafc95c0219f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mf[\"PassengerId\"].description = \"The ID of each passenger, as assigned by Pandas.\"\n",
    "\n",
    "print(mf.descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1c3ad724c9bfa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also set multiple descriptions of an already generated `MetaFrame` at once by passing in a dictionary of descriptions to its `descriptions` property. For example, we can set descriptions for the `Age` and `Name` columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e873f7362160a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mf.descriptions = {\"Name\": \"Name of the passenger\", \"Age\": \"Age of the passenger in years\"}\n",
    "\n",
    "print(mf.descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3b9eb9bbf6b17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Instead of a dictionary, it is also possible to pass in a list of descriptions to the `descriptions` property of a `MetaFrame`. \n",
    "\n",
    "This can only be done if the list has the same length as the number of variables. In other words, each description must be passed in. \n",
    "\n",
    "This can be useful for example when generating placeholder descriptions automatically through list comprehension, as is done in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b34ed6b11578c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mf.descriptions = [f\"Placeholder description for {var.name}\" for var in mf.meta_vars]\n",
    "\n",
    "print(mf.descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad00ca6c1fb3f2b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## The end\n",
    "\n",
    "That's it for this tutorial! You should now have a good understanding of how to use metasyn to generate synthetic data from a dataset. If you want to learn more, check out the [metasyn docs](https://metasynth.readthedocs.io/en/latest/).\n",
    "\n",
    "If you have any questions, feel free to [reach out](https://metasynth.readthedocs.io/en/latest/about/contact.html).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdb1107d616260949a63e5f4e2c5568939cf2f2c0d0d70930ae22d4d9fd1a8a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
