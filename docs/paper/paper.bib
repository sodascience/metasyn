@misc{bates2019ons,
  title={ONS methodology working paper series number 16—Synthetic data pilot},
  author={Bates, AG and Spakulov{\'a}, I and Dove, I and Mealor, A},
  year={2019}
}

@inproceedings{dwork2006differential,
  title={Differential privacy},
  author={Dwork, Cynthia},
  booktitle={International colloquium on automata, languages, and programming},
  pages={1--12},
  year={2006},
  organization={Springer}
}

@book{dewolf2012statistical,
  title={Statistical disclosure control},
  author={de Wolf, Peter-Paul},
  year={2012},
  publisher={Wiley \& Sons, Chichester}
}

@article{sweeney2002k,
  title={k-anonymity: A model for protecting privacy},
  author={Sweeney, Latanya},
  journal={International journal of uncertainty, fuzziness and knowledge-based systems},
  volume={10},
  number={05},
  pages={557--570},
  year={2002},
  publisher={World Scientific}
}

@misc{bond2015guidelines,
  title={Guidelines for Output Checking. Eurostat},
  author={Bond, S and Brandt, M and de Wolf, PP},
  year={2015}
}

@article{dwork2010differential,
  title={Differential privacy for statistics: What we know and what we want to learn},
  author={Dwork, Cynthia and Smith, Adam},
  journal={Journal of Privacy and Confidentiality},
  volume={1},
  number={2},
  year={2010}
}

@book{hastie2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
  volume={2},
  year={2009},
  publisher={Springer}
}

@inproceedings{akaike1973information,
  title={Information theory and an extension of the maximum likelihood principle},
  author={Akaike, H},
  booktitle={2nd International Symposium on Information Theory},
  pages={267--281},
  year={1973},
  organization={Akad{\'e}miai Kiad{\'o} Location Budapest, Hungary}
}

@article{neath2012bayesian,
  title={The Bayesian information criterion: background, derivation, and applications},
  author={Neath, Andrew A and Cavanaugh, Joseph E},
  journal={Wiley Interdisciplinary Reviews: Computational Statistics},
  volume={4},
  number={2},
  pages={199--203},
  year={2012},
  publisher={Wiley Online Library}
}
@software{vink2024polars,
  author       = {Ritchie Vink and
                  Stijn de Gooijer and
                  Alexander Beedie and
                  Marco Edward Gorelli and
                  Weijie Guo and
                  J van Zundert and
                  Orson Peters and
                  Gert Hulselmans and
                  nameexhaustion and
                  Cory Grinstead and
                  Marshall and
                  Gijs Burghoorn and
                  chielP and
                  Itamar Turner-Trauring and
                  Matteo Santamaria and
                  Daniël Heres and
                  Lawrence Mitchell and
                  Josh Magarick and
                  ibENPC and
                  Karl Genockey and
                  Moritz Wilksch and
                  Jorge Leitao and
                  Mick van Gelderen and
                  Petros Barbagiannis and
                  Oliver Borchert and
                  deanm0000 and
                  Jonas Haag and
                  Henry Harbeck and
                  Liam Brannigan},
  title        = {pola-rs/polars: Python Polars},
  year         = 2024,
  publisher    = {Zenodo},
  version      = {py-1.4.1},
  doi          = {10.5281/zenodo.7697217},
  url          = {https://doi.org/10.5281/zenodo.7697217}
}

@article{wickham2014tidy,
 title={Tidy Data},
 volume={59},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v059i10},
 doi={10.18637/jss.v059.i10},
 abstract={A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
 number={10},
 journal={Journal of Statistical Software},
 author={Wickham, Hadley},
 year={2014},
 pages={1–23}
}

# alternative synthetic data packages
@article{nowok2016synthpop,
  title={synthpop: Bespoke creation of synthetic data in R},
  author={Nowok, Beata and Raab, Gillian M and Dibben, Chris},
  journal={Journal of statistical software},
  volume={74},
  pages={1--26},
  year={2016}
}

@article{templ2017simulation,
  title={Simulation of synthetic complex data: The R package simPop},
  author={Templ, Matthias and Meindl, Bernhard and Kowarik, Alexander and Dupriez, Olivier},
  journal={Journal of Statistical Software},
  volume={79},
  number={10},
  pages={1--38},
  year={2017},
  publisher={UCLA, Dept. of Statistics}
}

@inproceedings{ping2017datasynthesizer,
  title={Datasynthesizer: Privacy-preserving synthetic datasets},
  author={Ping, Haoyue and Stoyanovich, Julia and Howe, Bill},
  booktitle={Proceedings of the 29th International Conference on Scientific and Statistical Database Management},
  pages={1--5},
  year={2017}
}

@article{vankesteren2024democratize,
  title={To democratize research with sensitive data, we should make synthetic data more accessible},
  author={{van Kesteren}, Erik-Jan},
  journal={arXiv preprint arXiv:2404.17271},
  year={2024}
}